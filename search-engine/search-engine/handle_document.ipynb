{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本处理\n",
    "## 从词到词项\n",
    "- 搜索引擎之所以有效的原因，是文本的很多含义通过词语出现和共现的次数获得。\n",
    "- 理解文本的统计性质是理解检索模型和排序算法的基础。\n",
    "\n",
    "## 文本统计\n",
    "### Zipf's Law\n",
    "Zipf's Law:第r高频的词的出现次数与r成反比，或者说，一个词在词频统计表中的排名乘以它的词频(f)约等于一个常数(k):\n",
    "  - $r \\cdot f = k$\n",
    "\n",
    "Zipf 可表示为：$r \\cdot P_r = c$\n",
    "- 其中$P_r$表示第r高频词出现的概率\n",
    "- c是一常数，对于英语而言，$c \\approx 0.1$\n",
    "\n",
    "Zipf Law通常对排名靠前和靠后的预测不准确。\n",
    "\n",
    "$r \\cdot P_r$值的log-log图呈现一条直线。\n",
    "- $log P_r=log(c \\cdot r^{-1})=logc-logr$\n",
    "\n",
    "### 语料规模与词表大小关系Heaps(1978)\n",
    "Heaps(1978)发现，语料规模与词表大小的关系为：$v = k \\cdot n^\\beta$\n",
    "- v为词汇量大小\n",
    "- 语料中共有n个词\n",
    "- k和 $\\beta$是随着不同语料变化的参数\n",
    "- Heaps法则预测当语料规模很小时，新词数量增长非常快。随着语料规模变大，新词数量无限增长，但是增速会变慢。\n",
    "\n",
    "### 估计数据集和结果集大小\n",
    "- 假设词的出现彼此独立\n",
    "  - $P(a \\cap b \\cap c) = P(a) \\cdot P(b) \\cdot P(c)$\n",
    "  - $P(a) = \\frac{f_a}{N}$\n",
    "  - $P(b) = \\frac{f_b}{N}$\n",
    "  - $P(c) = \\frac{f_c}{N}$\n",
    "  - $f_{abc} = N \\cdot \\frac{f_a}{N} \\cdot \\frac{f_b}{N} \\cdot \\frac{f_c}{N}$ 用频率近似\n",
    "- 假设词的出现不独立\n",
    "  - $P(a \\cap b \\cap c) = P(a \\cap b) \\cdot P(c | a \\cap b)$\n",
    "- 估计文档总数\n",
    "  - $\\frac{f_{ab}}{N} = \\frac{f_a}{N} \\cdot \\frac{f_b}{N}$\n",
    "  - $N = \\frac{f_a \\cdot f_b}{f_{ab}}$\n",
    "\n",
    "## 文档解析\n",
    "- 词素切分：指从文档中的字符序列中获取词的过程。\n",
    "- 停用词去除\n",
    "  - 停用词(stopword):第一，这些功能词极其普遍。第二，由于它们的普遍性和功能，这些词很少单独表达文档相关程度的信息。\n",
    "- 词干提取（stemming）：获得一个词不同变形之间关系的文本处理过程。将一个词由变形（inflection）（如复数、时态）或者派生(derivation)产生的多种不同形式简化为一个共同的例子。\n",
    "- 短语和n-gram\n",
    "  - 词性标注器（part-of-speech tagger，POS）：根据上下文信息对文本中的每一个词赋予一个词性标记。一般的词性标记包括NN（单数名词）、NNS（复数名词）、VB（动词）、VBD（动词，过去时）、VBN（动词，过去分词）、IN（介词）、JJ（形容词）、CC（连词）、PRP（代词）和MD（情态动词）。\n",
    "  - 任何n个词的序列都构成一个短语。这就是所谓n-gram。两个词的序列称为bigram，三个词的序列称为trigram。\n",
    "  - 所有长度的n-gram构成一个Zipf分布，一些常见短语非常频繁，大量的短语只出现一次，n-gram（包括单个词）的“排名-频率”数据比只有词本身更符合Zipf分布。\n",
    "\n",
    "## 文档结构和标记\n",
    "- 从HTML tag得到的网页结构信息的有些部分，是排序算法用到的非常重要的特征。\n",
    "- XML：XQuery\n",
    "\n",
    "## 链接分析\n",
    "### 锚文本\n",
    "- 链接的锚文本集合可以作为链出网页额外的文本属性，可以在排序算法中使用。\n",
    "- 写锚文本的人一般不是目标网页的作者。这意味着锚文本可能是从另一个角度来描述目标网页。\n",
    "\n",
    "### PageRank\n",
    "网页u的PageRank一般公式：\n",
    "\n",
    "$PR(u) = \\frac{\\lambda}{N} + (1-\\lambda) \\cdot \\sum_{v \\in B_u} \\frac{PR(v)}{L_v}$\n",
    "\n",
    "- $B_u$：指向u的网页集合\n",
    "- $L_v$：网页v中包含的外链数\n",
    "- N：需要考虑的网页数\n",
    "- $\\lambda$：进入任何网页的概率，一般取0.15\n",
    "\n",
    "这个公式也可表达为矩阵等式：R=TR,R是矩阵T的特征向量。\n",
    "\n",
    "其中R为PageRank向量，T为随机游走模型转移概率矩阵。元素 $T_{ij}$ 表示网页i进入网页j的概率，并且\n",
    "\n",
    "$T_{ij}=\\frac{\\lambda}{N}+(1-\\lambda)\\frac{1}{L_i}$\n",
    "\n",
    "## 信息抽取\n",
    "`命名实体识别`（named entity recognition）：一个命名实体是表达特定应用感兴趣的某一个事物的词或词序列。最一般的例子是人名、公司名或机构名、地名、时间和日期表达式、数量和货币值。\n",
    "\n",
    "```\n",
    "Fred Smith,who lives at 10 Water Street,Springfield,MA, is a long-time collector of tropical fish.\n",
    "```\n",
    "\n",
    "`隐马尔可夫模型`的信息抽取：给定一个句子，找到一个实体类别序列，使得产生这个句子的概率最大。自由状态转移时产生的输出是可见的（可以被观察到的）：潜在的状态是隐藏的（hidden）。\n",
    "\n",
    "对于上面例子，识别器将找到：\n",
    "\n",
    "```\n",
    "<start><name><not-an-entity><location><not-an-entity><end>\n",
    "```\n",
    "时，对于那个模型，其概率最高。Viterbi算法可以在HMM模型中找到最大概率的状态序列。\n",
    "\n",
    "使用这种方法识别命名实体的核心问题是，句子模型中的概率必须从训练数据估计出来。为了估计转义和输出概率，使用人工标注了正确实体标签的文本作为训练数据。从这个训练数据，可以直接估计出某个类别产生词的概率（输出概率）和类别之间的转移概率。\n",
    "\n",
    "## 国际化\n",
    "字符编码是搜索引擎处理非英语语言时的核心问题。\n",
    "\n",
    "词素切分对于很多语言很重要，有其是CJK家族。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
