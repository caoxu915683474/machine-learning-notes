{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TOC -->\n",
    "\n",
    "- [5 Resampling Methods](#5-resampling-methods)\n",
    "    - [5.1 Cross-Validation](#51-cross-validation)\n",
    "        - [5.1.1 The Validation Set Approach](#511-the-validation-set-approach)\n",
    "        - [5.1.2 Leave-One-Out Cross-Validation](#512-leave-one-out-cross-validation)\n",
    "        - [5.1.3 k-Fold Cross-Validation](#513-k-fold-cross-validation)\n",
    "        - [5.1.4 Bias-Variance Trade-Off for k-Fold Cross-Validation](#514-bias-variance-trade-off-for-k-fold-cross-validation)\n",
    "    - [5.2 The Bootstrap](#52-the-bootstrap)\n",
    "    - [5.3 Lab: Cross-Validation and the Bootstrap](#53-lab-cross-validation-and-the-bootstrap)\n",
    "        - [5.3.1 The Validation Set Approach](#531-the-validation-set-approach)\n",
    "        - [5.3.2 Leave-One-Out Cross-Validation](#532-leave-one-out-cross-validation)\n",
    "        - [5.3.3 k-Fold Cross-Validation](#533-k-fold-cross-validation)\n",
    "        - [5.3.4 The Bootstrap](#534-the-bootstrap)\n",
    "\n",
    "<!-- /TOC -->\n",
    "\n",
    "# 5 Resampling Methods\n",
    "## 5.1 Cross-Validation\n",
    "### 5.1.1 The Validation Set Approach\n",
    "The validation set approach, displayed in Figure 5.1, is a very simple strategy for this task. It involves randomly dividing the available set of observations into two parts, a **training set** and a **validation set** or **hold-out set**. The model is fit on the training set, and the fitted model is used to predict the responses for the observations in the validation set. \n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-12-16/9297548.jpg)\n",
    "\n",
    "The validation set approach is conceptually simple and is easy to implement. But it has two potential drawbacks:\n",
    "\n",
    "1. As is shown in the right-hand panel of Figure 5.2, the validation estimate of the test error rate can be highly variable.\n",
    "1. In the validation approach, only a subset of the observations—those that are included in the training set rather than in the validation set—are used to fit the model. Since statistical methods tend to perform worse when trained on fewer observations, this suggests that the validation set error rate may tend to **overestimate** the test error rate for the model fit on the entire data set.\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-12-16/58592017.jpg)\n",
    "\n",
    "### 5.1.2 Leave-One-Out Cross-Validation\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-12-16/71374411.jpg)\n",
    "\n",
    "The **Leave-one-out cross-validation** (LOOCV) estimate for the test MSE is the average of these n test error estimates:\n",
    "\n",
    "$CV_{(n)}=\\frac{1}{n}\\sum_{i=1}^n MSE_i.\\ (5.1)$\n",
    "\n",
    "### 5.1.3 k-Fold Cross-Validation\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-12-16/85478205.jpg)\n",
    "\n",
    "$CV_{(K)}=\\frac{1}{K}\\sum_{i=1}^K MSE_i.\\ (5.3)$\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-12-16/31781928.jpg)\n",
    "\n",
    "### 5.1.4 Bias-Variance Trade-Off for k-Fold Cross-Validation\n",
    "There is a bias-variance trade-off associated with the choice of k in k-fold cross-validation. Typically, given these considerations, one performs k-fold cross-validation using k = 5 or k = 10, as these values have been shown empirically to yield test error rate estimates that suffer neither from excessively high bias nor from very high variance.\n",
    "\n",
    "## 5.2 The Bootstrap\n",
    "Suppose that we wish to invest a fixed sum of money in two financial assets that yield returns of X and Y , respectively, where X and Y are random quantities. We will invest a fraction α of our money in X, and will invest the remaining 1 − α in Y . Since there is variability associated with the returns on these two assets, we wish to choose α to minimize the total risk, or variance, of our investment. In other words, we want to minimize Var(αX + (1 − α)Y ). One can show that the value that minimizes the risk is given by\n",
    "\n",
    "$\\alpha=\\frac{\\sigma_Y^2-\\sigma_{XY}}{\\sigma_X^2+\\sigma_Y^2-2\\sigma_{XY}},\\ (5.6)$\n",
    "\n",
    "- $\\sigma_X^2$ =Var(X)\n",
    "- $\\sigma_Y^2$ =Var(Y)\n",
    "- $\\sigma_{XY}$ =Cov(X,Y)\n",
    "\n",
    "We can then estimate the value of α that minimizes the variance of our investment using\n",
    "\n",
    "$\\hat{\\alpha}=\\frac{\\hat{\\sigma}_Y^2-\\hat{\\sigma}_{XY}}{\\hat{\\sigma}_X^2+\\hat{\\sigma}_Y^2-2\\hat{\\sigma}_{XY}},\\ (5.7)$\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-12-16/2601333.jpg)\n",
    "\n",
    "To estimate the standard deviation of $\\hat{\\alpha}$, we repeated the process of simulating 100 paired observations of X and Y , and estimating α using (5.7), 1,000 times. We thereby obtained 1,000 estimates for α, which we can call $\\hat{\\alpha_1}, \\hat{\\alpha_2}, \\cdots, \\hat{\\alpha_{1000}}$. The mean over all 1,000 estimates for α is\n",
    "\n",
    "$\\hat{\\alpha}=\\frac{1}{1000}\\sum_{r=1}^{1000} \\hat{\\alpha_r}=0.5996$\n",
    "\n",
    "very close to α = 0.6, and the standard deviation of the estimates is\n",
    "\n",
    "$\\sqrt{\\frac{1}{1000-1}\\sum_{r=1}^{1000}(\\hat{\\alpha_r}-\\bar{\\alpha})^2}=0.083.$\n",
    "\n",
    "$SE(\\hat{\\alpha)} \\approx 0.083.$\n",
    "\n",
    "So roughly speaking, for a random sample from the population, we would expect $\\hat{\\alpha}$ to differ from α by approximately 0.08, on average.\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-12-16/19263120.jpg)\n",
    "\n",
    "The sampling is performed with **replacement**, which means that the same observation can occur more than once in the bootstrap data set.\n",
    "\n",
    "$SE_{B(\\hat{\\alpha})}=\\sqrt{\\frac{1}{B-1}\\sum_{r=1}^B(\\hat{\\alpha^{*r}}-\\frac{1}{B}\\sum_{r'=1}^B \\hat{\\alpha^{*r'}})^2}\\ (5.8)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Lab: Cross-Validation and the Bootstrap\n",
    "### 5.3.1 The Validation Set Approach\n",
    "We begin by using the sample() function to split the set of observations sample()\n",
    "into two halves, by selecting a random subset of 196 observations out of the original 392 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(ISLR)\n",
    "set.seed(1)\n",
    "train=sample(392,196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.fit=lm(mpg~horsepower ,data=Auto,subset=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the **mean()** function to calculate the MSE of the 196 observations in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "26.1414211520072"
      ],
      "text/latex": [
       "26.1414211520072"
      ],
      "text/markdown": [
       "26.1414211520072"
      ],
      "text/plain": [
       "[1] 26.14142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attach(Auto)\n",
    "mean((mpg-predict(lm.fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.8225850408262"
      ],
      "text/latex": [
       "19.8225850408262"
      ],
      "text/markdown": [
       "19.8225850408262"
      ],
      "text/plain": [
       "[1] 19.82259"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit2=lm(mpg~poly(horsepower ,2),data=Auto,subset=train)\n",
    "mean((mpg-predict(lm.fit2,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.7825166856023"
      ],
      "text/latex": [
       "19.7825166856023"
      ],
      "text/markdown": [
       "19.7825166856023"
      ],
      "text/plain": [
       "[1] 19.78252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit3=lm(mpg~poly(horsepower ,3),data=Auto,subset=train)\n",
    "mean((mpg-predict(lm.fit3,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we choose a different training set instead, then we will obtain somewhat different errors on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "23.2955851508862"
      ],
      "text/latex": [
       "23.2955851508862"
      ],
      "text/markdown": [
       "23.2955851508862"
      ],
      "text/plain": [
       "[1] 23.29559"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(2)\n",
    "train=sample(392,196)\n",
    "lm.fit=lm(mpg~horsepower, subset=train)\n",
    "mean((mpg-predict(lm.fit,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "18.9012408317778"
      ],
      "text/latex": [
       "18.9012408317778"
      ],
      "text/markdown": [
       "18.9012408317778"
      ],
      "text/plain": [
       "[1] 18.90124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit2=lm(mpg~poly(horsepower ,2),data=Auto,subset=train)\n",
    "mean((mpg-predict(lm.fit2,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.2573982608642"
      ],
      "text/latex": [
       "19.2573982608642"
      ],
      "text/markdown": [
       "19.2573982608642"
      ],
      "text/plain": [
       "[1] 19.2574"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit3=lm(mpg~poly(horsepower ,3),data=Auto,subset=train)\n",
    "mean((mpg-predict(lm.fit3,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>39.9358610211705</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.157844733353654</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit=glm(mpg~horsepower ,data=Auto)\n",
    "coef(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>39.9358610211705</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.157844733353654</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit=lm(mpg~horsepower ,data=Auto)\n",
    "coef(lm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **cv.glm()** function is part of the **boot** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2315135179292</li>\n",
       "\t<li>24.2311440937562</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 24.2311440937562\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 24.2311440937562\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 24.23114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(boot)\n",
    "glm.fit=glm(mpg~horsepower ,data=Auto)\n",
    "cv.err=cv.glm(Auto,glm.fit)\n",
    "cv.err$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2315135179293</li>\n",
       "\t<li>19.2482131244897</li>\n",
       "\t<li>19.3349840640291</li>\n",
       "\t<li>19.4244303104303</li>\n",
       "\t<li>19.0332138547041</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179293\n",
       "\\item 19.2482131244897\n",
       "\\item 19.3349840640291\n",
       "\\item 19.4244303104303\n",
       "\\item 19.0332138547041\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179293\n",
       "2. 19.2482131244897\n",
       "3. 19.3349840640291\n",
       "4. 19.4244303104303\n",
       "5. 19.0332138547041\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 19.24821 19.33498 19.42443 19.03321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv.error=rep(0,5)\n",
    "for (i in 1:5) {\n",
    "    glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)\n",
    "    cv.error[i]=cv.glm(Auto,glm.fit)$delta[1]\n",
    "}\n",
    "cv.error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 k-Fold Cross-Validation\n",
    "The **cv.glm()** function can also be used to implement k-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2051967567753</li>\n",
       "\t<li>19.1892390663471</li>\n",
       "\t<li>19.3066158967501</li>\n",
       "\t<li>19.3379909004929</li>\n",
       "\t<li>18.8791148363354</li>\n",
       "\t<li>19.0210341885228</li>\n",
       "\t<li>18.8960903802809</li>\n",
       "\t<li>19.7120146188182</li>\n",
       "\t<li>18.9514005667302</li>\n",
       "\t<li>19.501959228555</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2051967567753\n",
       "\\item 19.1892390663471\n",
       "\\item 19.3066158967501\n",
       "\\item 19.3379909004929\n",
       "\\item 18.8791148363354\n",
       "\\item 19.0210341885228\n",
       "\\item 18.8960903802809\n",
       "\\item 19.7120146188182\n",
       "\\item 18.9514005667302\n",
       "\\item 19.501959228555\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2051967567753\n",
       "2. 19.1892390663471\n",
       "3. 19.3066158967501\n",
       "4. 19.3379909004929\n",
       "5. 18.8791148363354\n",
       "6. 19.0210341885228\n",
       "7. 18.8960903802809\n",
       "8. 19.7120146188182\n",
       "9. 18.9514005667302\n",
       "10. 19.501959228555\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 24.20520 19.18924 19.30662 19.33799 18.87911 19.02103 18.89609 19.71201\n",
       " [9] 18.95140 19.50196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(17)\n",
    "cv.error.10=rep(0,10)\n",
    "for (i in 1:10) {\n",
    "    glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)\n",
    "    cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]\n",
    "}\n",
    "cv.error.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 The Bootstrap\n",
    "#### Estimating the Accuracy of a Statistic of Interest\n",
    "To illustrate the use of the bootstrap on this data, we must first create a function, **alpha.fn()**, which takes as input the (X,Y) data as well as a vector indicating which observations should be used to estimate α. The function then outputs the estimate for α based on the selected observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha.fn=function(data,index) {\n",
    "    X=data$X[index]\n",
    "    Y=data$Y[index]\n",
    "    return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.57583207459283"
      ],
      "text/latex": [
       "0.57583207459283"
      ],
      "text/markdown": [
       "0.57583207459283"
      ],
      "text/plain": [
       "[1] 0.5758321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha.fn(Portfolio,1:100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next command uses the sample() function to randomly select 100 ob- servations from the range 1 to 100, with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.596383302006392"
      ],
      "text/latex": [
       "0.596383302006392"
      ],
      "text/markdown": [
       "0.596383302006392"
      ],
      "text/plain": [
       "[1] 0.5963833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "alpha.fn(Portfolio,sample(100,100,replace=T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boot() function automates boot() this approach. Below we produce R = 1, 000 bootstrap estimates for α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Portfolio, statistic = alpha.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "     original        bias    std. error\n",
       "t1* 0.5758321 -7.315422e-05  0.08861826"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(Portfolio,alpha.fn,R=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final output shows that using the original data, $\\hat{\\alpha} = 0.5758$, and that the bootstrap estimate for $SE(\\hat{\\alpha})$ is 0.0886.\n",
    "\n",
    "#### Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>39.9358610211705</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.157844733353654</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn=function(data,index) {\n",
    "    return(coef(lm(mpg~horsepower ,data=data,subset=index)))\n",
    "}\n",
    "boot.fn(Auto,1:392)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **boot.fn()** function can also be used in order to create bootstrap estimates for the intercept and slope terms by randomly sampling from among the observations with replacement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>38.7387133554397</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.14819518636376</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 38.7387133554397\n",
       "\\item[horsepower] -0.14819518636376\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   38.7387133554397horsepower\n",
       ":   -0.14819518636376\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 38.7387134  -0.1481952 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "boot.fn(Auto,sample(392,392,replace=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>40.0383085722796</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.159610359262947</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 40.0383085722796\n",
       "\\item[horsepower] -0.159610359262947\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   40.0383085722796horsepower\n",
       ":   -0.159610359262947\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 40.0383086  -0.1596104 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn(Auto,sample(392,392,replace=T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the boot() function to compute the standard errors of 1,000 bootstrap estimates for the intercept and slope terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "      original      bias    std. error\n",
       "t1* 39.9358610  0.02972191 0.860007896\n",
       "t2* -0.1578447 -0.00030823 0.007404467"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(Auto, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>39.9358610   </td><td>0.717498656  </td><td> 55.65984    </td><td>1.220362e-187</td></tr>\n",
       "\t<tr><th scope=row>horsepower</th><td>-0.1578447   </td><td>0.006445501  </td><td>-24.48914    </td><td> 7.031989e-81</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 39.9358610    & 0.717498656   &  55.65984     & 1.220362e-187\\\\\n",
       "\thorsepower & -0.1578447    & 0.006445501   & -24.48914     &  7.031989e-81\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(>|t|) | \n",
       "|---|---|\n",
       "| (Intercept) | 39.9358610    | 0.717498656   |  55.65984     | 1.220362e-187 | \n",
       "| horsepower | -0.1578447    | 0.006445501   | -24.48914     |  7.031989e-81 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "            Estimate   Std. Error  t value   Pr(>|t|)     \n",
       "(Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187\n",
       "horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(mpg~horsepower ,data=Auto))$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we compute the bootstrap standard error estimates and the stan- dard linear regression estimates that result from fitting the quadratic model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "        original        bias     std. error\n",
       "t1* 56.900099702  6.098115e-03 2.0944855842\n",
       "t2* -0.466189630 -1.777108e-04 0.0334123802\n",
       "t3*  0.001230536  1.324315e-06 0.0001208339"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn=function(data,index) {\n",
    "    coefficients(lm(mpg~horsepower+I(horsepower^2),data=data,subset=index))\n",
    "}\n",
    "set.seed(1)\n",
    "boot(Auto, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>56.900099702 </td><td>1.8004268063 </td><td> 31.60367    </td><td>1.740911e-109</td></tr>\n",
       "\t<tr><th scope=row>horsepower</th><td>-0.466189630 </td><td>0.0311246171 </td><td>-14.97816    </td><td> 2.289429e-40</td></tr>\n",
       "\t<tr><th scope=row>I(horsepower^2)</th><td> 0.001230536 </td><td>0.0001220759 </td><td> 10.08009    </td><td> 2.196340e-21</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 56.900099702  & 1.8004268063  &  31.60367     & 1.740911e-109\\\\\n",
       "\thorsepower & -0.466189630  & 0.0311246171  & -14.97816     &  2.289429e-40\\\\\n",
       "\tI(horsepower\\textasciicircum{}2) &  0.001230536  & 0.0001220759  &  10.08009     &  2.196340e-21\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(>|t|) | \n",
       "|---|---|---|\n",
       "| (Intercept) | 56.900099702  | 1.8004268063  |  31.60367     | 1.740911e-109 | \n",
       "| horsepower | -0.466189630  | 0.0311246171  | -14.97816     |  2.289429e-40 | \n",
       "| I(horsepower^2) |  0.001230536  | 0.0001220759  |  10.08009     |  2.196340e-21 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                Estimate     Std. Error   t value   Pr(>|t|)     \n",
       "(Intercept)     56.900099702 1.8004268063  31.60367 1.740911e-109\n",
       "horsepower      -0.466189630 0.0311246171 -14.97816  2.289429e-40\n",
       "I(horsepower^2)  0.001230536 0.0001220759  10.08009  2.196340e-21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(mpg~horsepower+I(horsepower^2),data=Auto))$coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
