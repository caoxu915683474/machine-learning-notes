{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最大后验估计(Maximum-a-Posteriori (MAP) Estimation)\n",
    "最大后验估计是根据经验数据获得对难以观察的量的点估计。与最大似然估计类似，但是最大的不同时，最大后验估计的融入了要估计量的先验分布在其中。故最大后验估计可以看做规则化的最大似然估计。\n",
    "\n",
    "首先，我们回顾上篇文章中的最大似然估计，假设x为独立同分布的采样，θ为模型参数,f为我们所使用的模型。那么最大似然估计可以表示为：\n",
    "\n",
    "$\\hat{\\theta}_{MLE}(x)=arg max_{\\theta} f(x|\\theta)$\n",
    "\n",
    "现在，假设θ的先验分布为g。通过贝叶斯理论，对于θ的后验分布如下式所示：\n",
    "\n",
    "$\\theta \\mapsto f(\\theta|x)=\\frac{f(x|\\theta)g(\\theta)}{\\int_{\\theta \\in \\Theta} f(x|\\theta ')g(\\theta ')d\\theta '}$\n",
    "\n",
    "最大后验分布的目标为：\n",
    "\n",
    "$\\hat{\\theta}_{MAP}(x)=arg max_{\\theta} \\frac{f(x|\\theta)g(\\theta)}{\\int_{\\theta}f(x|\\theta ')g(\\theta ')d\\theta '}=arg max_{\\theta} f(x|\\theta)g(\\theta)$\n",
    "\n",
    "注：最大后验估计可以看做贝叶斯估计的一种特定形式。\n",
    "\n",
    "举例来说：\n",
    "\n",
    "假设有五个袋子，各袋中都有无限量的饼干(樱桃口味或柠檬口味)，已知五个袋子中两种口味的比例分别是\n",
    "\n",
    "\n",
    "樱桃 100%\n",
    "\n",
    "樱桃 75% + 柠檬 25%\n",
    "\n",
    "樱桃 50% + 柠檬 50%\n",
    "\n",
    "樱桃 25% + 柠檬 75%\n",
    "\n",
    "柠檬 100%\n",
    "\n",
    "　　\n",
    "如果只有如上所述条件，那问从同一个袋子中连续拿到2个柠檬饼干，那么这个袋子最有可能是上述五个的哪一个？\n",
    "\n",
    "我们首先采用最大似然估计来解这个问题，写出似然函数。假设从袋子中能拿出柠檬饼干的概率为p(我们通过这个概率p来确定是从哪个袋子中拿出来的)，则似然函数可以写作\n",
    "\n",
    "p(两个柠檬饼干|袋子)=$p^2$\n",
    "\n",
    "由于p的取值是一个离散值，即上面描述中的0,25%，50%，75%，1。我们只需要评估一下这五个值哪个值使得似然函数最大即可，得到为袋子5。这里便是最大似然估计的结果。\n",
    "\n",
    "上述最大似然估计有一个问题，就是没有考虑到模型本身的概率分布，下面我们扩展这个饼干的问题。\n",
    "\n",
    "假设拿到袋子1或5的机率都是0.1，拿到2或4的机率都是0.2，拿到3的机率是0.4，那同样上述问题的答案呢？这个时候就变MAP了。我们根据公式\n",
    "\n",
    "$\\hat{\\theta}_{MAP}(x)=arg max_{\\theta} \\frac{f(x|\\theta)g(\\theta)}{\\int_{\\theta}f(x|\\theta ')g(\\theta ')d\\theta '}$\n",
    "\n",
    "写出我们的MAP函数。\n",
    "\n",
    "$MAP=p^2 \\times g$\n",
    "\n",
    "根据题意的描述可知，p的取值分别为0,25%，50%，75%，1，g的取值分别为0.1，0.2,0.4,0.2,0.1.分别计算出MAP函数的结果为：0,0.0125,0.125,0.28125,0.1.由上可知，通过MAP估计可得结果是从第四个袋子中取得的最高。\n",
    "\n",
    "上述都是离散的变量，那么连续的变量呢？假设$x_1,x_2,...,x_n$为独立同分布的$N(\\mu,\\sigma_v^2)$，μ有一个先验的概率分布为$N(\\mu_0,\\sigma_m^2)$。那么我们想根据$x_1,x_2,...,x_n$来找到μ的最大后验概率。根据前面的描述，写出MAP函数为：\n",
    "\n",
    "$g(\\mu)f(x|\\mu)=g(\\mu)L(\\mu)=\\frac{1}{\\sqrt{2\\pi}\\sigma_m} exp(-\\frac{1}{2}(\\frac{\\mu-\\mu_0}{\\sigma_m})^2)\\prod_{j=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma_v} exp(-\\frac{1}{2}(\\frac{x_j-\\mu}{\\sigma_v})^2)$\n",
    "\n",
    "此时我们在两边取对数可知。所求上式的最大值可以等同于求\n",
    "\n",
    "$\\sum_{j=1}^n(\\frac{x_j-\\mu}{\\sigma_v})^2+(\\frac{\\mu-\\mu_0}{\\sigma_m})$\n",
    "\n",
    "的最小值。求导可得所求的μ为\n",
    "\n",
    "$\\hat{\\mu_{MAP}}=\\frac{n\\sigma_m^2}{n\\sigma_m^2+\\sigma_v^2}(\\frac{1}{n}\\sum_{j=1}^n x_j)+\\frac{\\sigma_v^2}{n\\sigma_m^2+\\sigma_v^2}\\mu_0$\n",
    "\n",
    "以上便是对于连续变量的MAP求解的过程。\n",
    "\n",
    "在MAP中我们应注意的是：\n",
    "\n",
    ">MAP与MLE最大区别是MAP中加入了模型参数本身的概率分布，或者说。MLE中认为模型参数本身的概率的是均匀的，即该概率为一个固定值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
