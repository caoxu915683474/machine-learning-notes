{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归分析(regression analysis)与相关分析(correlation analysis)\n",
    "* 回归分析:描述一个或多个自变量的变化是如何影响因变量的一种方法。\n",
    "* 相关分析:描述两个数值变量间关系的强度。\n",
    "\n",
    "## 回归方程概念\n",
    "* 当这些数据沿一条直线排列时，我们可以计算一个系数来衡量两个变量间的关系。对于两个数值变量，计算出来的系数记作r，简称其为相关系数(correlation coefficient)。也可称为Pearson相关系数(Pearson’s correlation coefficient)。\n",
    "* 一条回归直线的方程可以写作：因变量 = 截距 + 斜率 x 自变量，用符号表示：y = a + bx。其中自变量的斜率称为回归系数(regression coefficient)。\n",
    "* 计算回归直线：最小二乘原理。所作的这条直线使这些直线的距离的平方和最小。\n",
    "* 把自变量的值代入回归直线的方程就得到了因变量的预测值(predicted value)。\n",
    "* 残差变量(residual variable)包含了除自变量外其他所有变量对因变量的效应。残差变量的效应是由一个观测点到回归直线的垂直距离，它们的和称作残差平方和(residual sum of squares)，有时也称为误差平方和。\n",
    "* 总平方和(total sum of squares)度量了自变量和残差变量在因变量上的效应，它等于![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/97046408.jpg) 。\n",
    "\n",
    "## 回归方程公式\n",
    "有两个变量x和y的n个观测数据可以用下面的符号表示：\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/28521088.jpg)\n",
    "\n",
    "- 相关系数和回归系数(斜率)\n",
    "    - 相关系数：$r=\\frac{\\sum{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sqrt{\\sum{(x_i-\\bar{x})^2}\\sum{(y_i-\\bar{y})^2}}}=\\frac{n\\sum{x_iy_i}-\\sum{x_i}\\sum{y_i}}{\\sqrt{[n\\sum{x_i^2}-(\\sum{x_i})^2][n\\sum{y_i^2}-(\\sum{y_i})^2]}}$\n",
    "    - 回归直线的斜率：$b=\\frac{\\sum{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sum{(x_i-\\bar{x})^2}}=\\frac{n\\sum{x_iy_i}-\\sum{x_i}\\sum{y_i}}{n\\sum{x_i^2}-(\\sum{x_i})^2}$\n",
    "    - r和b有关系：$b=r\\frac{s_y}{s_x}$，两个s是两个变量x和y的标准差。\n",
    "- 回归直线的截距:$a=\\bar{y}-b\\bar{x}$\n",
    "- 平方和\n",
    "    - 总平方和(TSS)= $\\sum{(y_i-\\bar{y})^2}$\n",
    "    - 回归平方和(RegrSS)= $\\sum{(a+bx_i-\\bar{y})^2}$，就是$b(x_i-\\bar{x})$的平方和，x即Fat\n",
    "    - 残差平方和(RSS)= $\\sum{(y_i-a-bx_i)^2}$\n",
    "    - $r^2=\\frac{RegrSS}{TSS}$\n",
    "\n",
    "## 回归分析例子\n",
    "表10.1点心食物中的热量和脂肪:\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/8663852.jpg)\n",
    "\n",
    "对应的散点图:\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/33779595.jpg)\n",
    "\n",
    "- $\\bar{x}=11.8125$\n",
    "- $y=216.3125$\n",
    "- $\\sum{(x_i-\\bar{x})(y_i-\\bar{y})}=8642.938$\n",
    "- $\\sum{(x_i-\\bar{x})^2}=566.4375$\n",
    "- $\\sum{(y_i-\\bar{y})^2}=159059.4$\n",
    "- $r=\\frac{8642.938}{\\sqrt{159059.4 \\times 566.4375}}=0.91$\n",
    "- $b=\\frac{8642.938}{566.4375}=15.3$\n",
    "- $a=216.3125-15.3 \\times 11.8125=36.1$\n",
    "\n",
    "回归方程为：![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/10010060.jpg)\n",
    "\n",
    "用符号表示： $\\hat{y}=36.1+15.3x$\n",
    "\n",
    "## 相关系数r2：效果的度量\n",
    "基于表10.1数据计算数据的平方和及比例，而相关系数$r^2={0.91}^2=0.83$ ，恰好是表10.4中由脂肪效应贡献的比例：\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/75122882.jpg)\n",
    "\n",
    "## 总体的回归系数β的置信区间(t统计量)\n",
    "* b的置信区间：$b-t^{*}s_b$ 到 $b+t^{*}s_b$\n",
    "* 这里b是观测的回归系数， $b^{*}$是从一个t分布表得到的自由度为n-2的t统计量的1-a/2分为点的值， $s_b$是b的标准误差，$s_b=\\sqrt{\\frac{RSS/(n-2)}{\\sum{(x_i-\\bar{x})^2}}}$ \n",
    "* 样本回归系数是15.3卡/克。我们计算的样本误差为4.0。从而总体的斜率β的置信区间为15.3-4.0=11.3卡/克到15.3+4.0=19.3卡/克。我们希望，区间[11.3,19.3]很可能是所有95%地包含总体的回归系数β的区间中的一个，而不是那些很少的不包含β的区间中的一个。\n",
    "\n",
    "## 假设检验(t检验和F检验)\n",
    "* 对于我们的脂肪含量和热量的例子，由回归系数b的值得到：$t=\\frac{b}{s_b}=\\frac{15.3}{1.85}=8.24$\n",
    "* 也可由相关系数r出发由下面公式得到相同的t值：$t=\\frac{r}{\\sqrt{\\frac{1-r^2}{n-2}}}=\\frac{0.910}{\\sqrt{\\frac{1-0.829}{16-2}}}=8.24$\n",
    "* 用t进行假设检验：零假设：认为两变量间没有关系。为了检验零假设，我们可以用观测的样本回归系数b，也可以用观测的样本相关系数r。它们都得到相同的t统计量值。从得到的t统计量的值，我们可以计算p-值并对零假设下结论。这里，b=15.3卡/克，这个b值相应于t=8.24，(df=n-2=14)。类似地，r=0.91，也得到相应的t=8.24。从[t-分布表][1]，可以得到t≥8.24的概率小于0.0001。这意味着，仅仅由于偶然而出现观测到的或更强的样本关系几乎不可能。由于p-值很小，我们拒绝认为两变量间无关的零假设。\n",
    "* 利用[F进行假设检验][2]：基于表10.4，我们再加上三列(表10.5)。表有\"均方\"(Mean square)的那一列是由每个平方和除以它们相应的自由度得到。由于回归平方和只有一个自由度，所以其均方还是131878.残差均方(RMS)是27182/14=1941.6.然后用回归的均方除以残差的均方就得到F=131878/1941.6=67.90。它有两个自由度，分别是1和14.最后，F≥67.90的概率小于0.0001，所以拒绝零假设。\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/72416010.jpg)\n",
    "\n",
    "## 使用虚拟变量\n",
    "* 一个虚拟变量(dummy variable)是一个只有两个数值的变量，它经常用来表示一个有两类的分类变量。分类变量中，第一类的所有观测都取虚拟变量的一个值，第二类的所有观测都取虚拟变量的另一个值。\n",
    "* 自变量是有两个取值的分类变量和因变量是数值变量。在这里，作为自变量的地域有两个取值：东海岸和西海岸。这是一个分类变量。因变量是温度的变化范围，它是一个数值变量。\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/49315774.jpg)\n",
    "\n",
    "* 因变量是有两个取值的分类变量和自变量是数值变量。在这里，因变量(汽车产地)是一个具有两类的分类变量，自变量(驱动比)是一个数值变量。对这种情形，这些数据的散点图是非线性的，我们不可能拟合一条穿过这些点的直线，因为散点图中所有的点都落在两条水平的直线上。一条是y=0另一条是y=1。对于这些数据，我们拟合一条S形的曲线。这种类型的分析称作逻辑回归(logistic regression)。这条曲线从图的右上角的点开始沿这些点，然后很快的下降到图左下角的那些点。这条曲线比任何一条通过这些点的直线的残差都小。\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/26600606.jpg)\n",
    "\n",
    "[1]: http://zh.wikipedia.org/wiki/学生t-分布\n",
    "[2]: http://zh.wikipedia.org/wiki/F-分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
