{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 相关与非参数检验-回归\n",
    "## 线性方程与回归\n",
    "定义 用于找出一组数据的最佳拟合直线的统计技术被称为`回归`，作为结果的直线被称为回归线。\n",
    "\n",
    "### 线性方程\n",
    "通常，在两个变量X与Y之间的线性关系，可以被表示为公式：$Y=bX+a\\ (17.1)$，a与b是固定的常数。\n",
    "\n",
    "### 最小二乘\n",
    "为了确定线与数据点的拟合度，第一步是定义线与每个数据点之间的算术距离。对于数据中的每个X值，线性方程将在线上确定Y值。这个值是预测的Y值，被称为$\\hat{Y}$。在这个预测值与数据的实际Y值之间的距离为：\n",
    "\n",
    "距离值=$Y-\\hat{Y}$\n",
    "\n",
    "误差平方和=$\\sum(Y-\\hat{Y})^2$\n",
    "\n",
    "现在我们可以将最佳拟合线定义为误差平方和最小的那条线。相应的方法被称为`最小二乘法`。\n",
    "\n",
    "用符号表示，线性方程的形式为：$\\hat{Y}=bX+a$\n",
    "\n",
    "$b=\\frac{SP}{SS_X}\\ (17.2)$，其中SP是积和，$SS_X$是X的平方和。\n",
    "\n",
    "另一个经常使用的斜率公式是基于X和Y的标准差。这个公式是：$b=r\\frac{S_Y}{S_X}\\ (17.3)$\n",
    "\n",
    "其中$S_Y$是Y分数的标准差，$S_X$是X分数的标准差。公式中参数a的值为：$a=M_Y-bM_X\\ (17.4)$\n",
    "\n",
    "定义 `Y的回归方程`是线性方程$\\hat{Y}=bX+a\\ (17.5)$。其中常数b由公式17.2或17.3确定，常数a由公式17.4确定。这个公式能得出在数据点与直线之间的最小的平方误差。\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/68762089.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/38971942.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/31167296.jpg)\n",
    "\n",
    "### 标准化回归方程\n",
    "迄今为止，我们讲过了原始数据的回归方程，然而，研究者偶尔也会在找出回归方程之前将X与Y标准化为z分数。这样，得到的公式通常被称为`标准化回归方程`，与原始分数版本相比，它的形式大大被简化了。因为z分数是标准化的。具体来说，一组z分数的平均数总是0，标准差总是1.因此，\u001b标准化回归方程变成了：\n",
    "\n",
    "$\\hat{z}_Y=\\beta z_X\\ (17.6)$\n",
    "\n",
    "首先注意，我们现在用每个X值的z分数来预测相应的Y值的z分数。另外，注意，斜率常数在原始分数公式中用b表示，现在\b则\b用$\\beta$表示。因为两组z分数的平均数都是零，因此回归方程中的常数a消失了。最后，当变量X被用来预测变量Y时，$\\beta$的值等于X与Y的皮尔逊相关。因此，标准回归方程也可以写成：\n",
    "\n",
    "$\\hat{z}_Y=r z_X\\ (17.7)$\n",
    "\n",
    "因为将原始分数变为z分数的过程往往\u001b繁琐，\b研究者通常用计算原始分数回归方程的版本（公式17.5）来代替标准化形式。\n",
    "\n",
    "### 估计的标准误\n",
    "定义 `估计的标准误`衡量了回归线与实际的数据点之间的标准距离。\n",
    "\n",
    "为了计算估计的标准误，我们首先需要找出离差的平方和（SS）。离差即实际的Y（从数据中得到的）与预测$\\bar{Y}$（从回归线上得到的）之间的距离。其平方和通常被称为SS残差。\n",
    "\n",
    "SS残差=$\\sum(Y-\\bar{Y})^2\\ (17.8)$\n",
    "\n",
    "得到的SS值然后除以其自由度，得到了方差：\n",
    "\n",
    "方差=$\\frac{SS}{df}$\n",
    "\n",
    "估计的标准误的自由度是df=n-2。自由度为n-2，而不是习惯的n-1，理由是我们现在只测量到一条线的离差，而不是到平均数的离差。我们必须知道SP才能找出回归线的斜率（公式中的b值）。而为了计算SP，你必须同时知道X与Y的平均数。找出这两个平均数对数据的变异性加上了两重限制，因此只有n-2的自由度（对SS残差df=n-2的一个更直观的解释是，恰好两个点确定一条直线。如果自由两个数据点，那么，它们总是能完美地与直线拟合，因此将不存在误差。只有当你有多于两个点时，才存在一些决定最佳拟合线的自由）。\n",
    "\n",
    "\n",
    "计算估计的标准误的最后一步是计算方差的平方根，来得出标准距离。最好的公式是：\n",
    "\n",
    "估计的标准误=$\\sqrt{\\frac{SS_{residual}}{df}}=\\sqrt{\\frac{\\sum(Y-\\hat{Y})^2}{n-2}}\\ (17.9)$\n",
    "\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/3435133.jpg)\n",
    "\n",
    "### 标准误与相关的关系\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/62556346.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/10018693.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/16429400.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/7119886.jpg)\n",
    "\n",
    "## 回归方程的显著性检验：回归分析\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/96311274.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/87104685.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/28348004.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/62439393.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/83020070.jpg)\n",
    "\n",
    "## 有两个预测变量的多元回归\n",
    "### 两个预测变量的回归方程\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/5248473.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/80581151.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/51273322.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/43744723.jpg)\n",
    "\n",
    "### 回归方差所占的百分比与残差\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/92716831.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/24074024.jpg)\n",
    "\n",
    "### 根据残差计算$R^2$与$1-R^2$\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/9263493.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/93640934.jpg)\n",
    "\n",
    "### 估计的标准误\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/27284727.jpg)\n",
    "\n",
    "### 多元回归方程的显著性检验：回归分析\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/81610865.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/4215948.jpg)\n",
    "\n",
    "## 评估每个预测值的贡献\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/13325829.jpg)\n",
    "![](http://ou8qjsj0m.bkt.clouddn.com//17-10-26/73130482.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
