{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Parsing for Single-Relation Question Answering\n",
    "\n",
    "    Wen-tau Yih \n",
    "    Xiaodong He \n",
    "    Christopher Meek\n",
    "    2014\n",
    "\n",
    "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/SingleRelationQA-YihHeMeek-ACL14.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "1. 回答single-relation questions: r(e1, e2)\n",
    "1. entity-mention pair: e1和e2\n",
    "1. pattern–relation pair: r和e1e2\n",
    "1. train两个CNN semantic model识别entity-mention pair和pattern–relation pair\n",
    "1. 得到了这两个pair再套lambda expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition & Approach\n",
    "In this paper, we focus on using a knowledge base to answer `single-relation` questions.\n",
    "\n",
    "An example of a single-relation question is “When were DVD players invented?” The entity is `dvd-player` and the relation is `be-invent-in`. The answer can thus be described as the following lambda expression:\n",
    "\n",
    "    λx. be-invent-in(dvd-player, x)\n",
    "\n",
    "```\n",
    "    Q → RP ∧ M (1) \n",
    "    RP → when were X invented (2) \n",
    "    M → dvd players (3)\n",
    "when were X invented\n",
    "    → be-invent-in (4) \n",
    "dvd players\n",
    "    → dvd-player (5)\n",
    "```\n",
    "\n",
    "Figure 1: A potential semantic parse of the question “When were DVD players invented?”\n",
    "\n",
    "A knowledge base in this work can be simply viewed as a collection of binary relation instances in the form of r(e1, e2), where r is the relation and e1 and e2 are the first and second entity arguments.\n",
    "\n",
    "Given a question, we first separate it into two disjoint parts: the `entity mention` and the `relation pattern`. The entity mention is a subsequence of consecutive words in the question, where the relation pattern is the question where the mention is substituted by a special symbol.\n",
    "\n",
    "## Convolutional Neural Network based Semantic Model\n",
    "![1](http://ou8qjsj0m.bkt.clouddn.com//17-8-6/45019825.jpg)\n",
    "\n",
    "Figure 2: The CNNSM maps a variable-length word sequence to a low-dimensional vector in a latent semantic space. A word contextual window size (i.e., the receptive field) of three is used in the illustration. Convolution over word sequence via learned matrix Wc is performed implicitly via the earlier word hashing layer’s mapping with a local receptive field. The max operation across the sequence is applied for each of 500 feature dimensions separately.\n",
    "\n",
    "Given a pattern and a relation, we compute their relevance score by measuring the cosine similarity between their semantic vectors. The semantic relevance score between a pattern Q and a relation R is defined as the cosine score of their semantic vectors $y_Q$ and $y_R$.\n",
    "\n",
    "We train two CNN semantic models from sets of pattern–relation and mention–entity pairs, respectively.\n",
    "\n",
    "The posterior probability of the positive relation given the pattern is computed based on the cosine scores using softmax:\n",
    "\n",
    "$P(R^{+}|Q)=\\frac{exp(\\gamma \\cdot cos(y_{R^{+}},y_Q))}{\\sum_{R'} exp(\\gamma \\cdot cos(y_{R'},y_Q))}$\n",
    "\n",
    "where γ is a scaling factor set to 5. Model training is done by maximizing the log-posteriori using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
