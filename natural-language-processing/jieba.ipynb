{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结巴中文分词\n",
    "\n",
    "https://github.com/fxsjy/jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.分词\n",
    "1. `jieba.cut` 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型\n",
    "1. `jieba.cut_for_search` 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细\n",
    "1. 待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8\n",
    "1. `jieba.cut` 以及 `jieba.cut_for_search` 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用\n",
    "1. `jieba.lcut` 以及 `jieba.lcut_for_search` 直接返回 list\n",
    "1. `jieba.Tokenizer(dictionary=DEFAULT_DICT)` 新建自定义分词器，可用于同时使用不同词典。`jieba.dt` 为默认分词器，所有全局分词相关函数都是该分词器的映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/pb/0wpsfs4x5cq3l5jrspxp9v4r0000gn/T/jieba.cache\n",
      "Loading model cost 0.469 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode(HMM=False): 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Full Mode(HMM=True): 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "Default Mode: 他, 来到, 了, 网易, 杭研, 大厦\n",
      "Search Engine Mode: 小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "from __future__ import print_function, unicode_literals\n",
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True, HMM=False)\n",
    "print(\"Full Mode(HMM=False): \" + \"/ \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True, HMM=True)\n",
    "print(\"Full Mode(HMM=True): \" + \"/ \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\"Default Mode: \" + \", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\"Search Engine Mode: \" + \", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.添加自定义词典\n",
    "### 2.1 载入词典\n",
    "- 开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率\n",
    "- 用法： `jieba.load_userdict(file_name)` # file_name 为文件类对象或自定义词典的路径\n",
    "- 词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。\n",
    "- 词频省略时使用自动计算的能保证分出该词的词频。\n",
    "\n",
    "例如：\n",
    "\n",
    "```\n",
    "创新办 3 i\n",
    "云计算 5\n",
    "凱特琳 nz\n",
    "台中\n",
    "```\n",
    "\n",
    "### 2.2 调整词典\n",
    "- 使用 `add_word(word, freq=None, tag=None)` 和 del_word(word) 可在程序中动态修改词典。\n",
    "- 使用 `suggest_freq(segment, tune=True)` 可调节单个词语的词频，使其能（或不能）被分出来。\n",
    "- 注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。\n",
    "\n",
    "使用默认分词，“创新办”、“云计算”、“八一双鹿”、“韩玉赏鉴”、“凱特琳”是分错的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新/办/主任/也/是/云/计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定义词/库中/也/增加/了/此/词为/N/类/\n",
      "/「/台/中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨/烯/」/；/此時/又/可以/分出/來凱/特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "\"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "\"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\"\n",
    ")\n",
    "\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入“凱特琳”后："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新/办/主任/也/是/云/计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定义词/库中/也/增加/了/此/词为/N/类/\n",
      "/「/台/中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨/烯/」/；/此時/又/可以/分出/來/凱特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "jieba.add_word('凱特琳')  \n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除“凱特琳”后："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新/办/主任/也/是/云/计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定义词/库中/也/增加/了/此/词为/N/类/\n",
      "/「/台/中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨/烯/」/；/此時/又/可以/分出/來/凱特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "jieba.del_word('凱特琳')\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入“石墨烯”后："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新/办/主任/也/是/云/计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定义词/库中/也/增加/了/此/词为/N/类/\n",
      "/「/台/中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨烯/」/；/此時/又/可以/分出/來/凱特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "jieba.add_word('石墨烯')\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入词典："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "云计算 5\r\n",
      "李小福 2 nr\r\n",
      "创新办 3 i\r\n",
      "easy_install 3 eng\r\n",
      "好用 300\r\n",
      "韩玉赏鉴 3 nz\r\n",
      "八一双鹿 3 nz\r\n",
      "台中\r\n",
      "凱特琳 nz\r\n",
      "Edu Trust认证 2000\r\n"
     ]
    }
   ],
   "source": [
    "!cat userdict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新办/主任/也/是/云计算/方面/的/专家/;/ /什么/是/八一双鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉赏鉴/”/的/标题/，/在/自定义词/库中/也/增加/了/此/词为/N/类/\n",
      "/「/台中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨烯/」/；/此時/又/可以/分出/來/凱特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict(\"userdict.txt\")\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "调节单个词语的词频:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中将/出错/。\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq(('中', '将'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中/将/出错/。\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「/台中/」/正确/应该/不会/被/切开\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq('台中', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「/台中/」/正确/应该/不会/被/切开\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 关键词提取\n",
    "### 3.1 基于 TF-IDF 算法的关键词抽取\n",
    "\n",
    "```py\n",
    "jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())\n",
    "```\n",
    "\n",
    "- `sentence` 为待提取的文本\n",
    "- `topK` 为返回几个 TF/IDF 权重最大的关键词，默认值为 20\n",
    "- `withWeight` 为是否一并返回关键词权重值，默认值为 False\n",
    "- `allowPOS` 仅包括指定词性的词，默认值为空，即不筛选\n",
    "- `jieba.analyse.TFIDF(idf_path=None)` 新建 TFIDF 实例，idf_path 为 IDF 频率文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "艾伦·麦席森·图灵，1912年生于英国伦敦，1954年死于英国的曼彻斯特，他是计算机逻辑的奠基者，许多人工智能的重要方法也源自于这位伟大的科学家，被誉为计算机科学之父、人工智能之父。计算机逻辑的奠基者，提出了“图灵机”和“图灵测试”等重要概念。人们为纪念其在计算机领域的卓越贡献而专门设立了“图灵奖”。艾伦·麦席森·图灵是一名男同性恋者，同时还是一位世界级的长跑运动员。他的马拉松最好成绩是2小时46分3秒，比1948年奥林匹克运动会金牌成绩慢11分钟。1948年的一次跨国赛跑比赛中，他跑赢了同年奥运会银牌得主汤姆·理查兹（Tom Richards）。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('turing.txt', 'r') as f:\n",
    "    sentences = f.read()\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码示例 （关键词提取）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图灵/麦席森/1948/艾伦/奠基者/人工智能/逻辑/成绩/计算机/计算机领域\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "\n",
    "tags = jieba.analyse.extract_tags(sentences, topK=10)\n",
    "print('/'.join(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关键词提取所使用逆向文件频率（IDF）文本语料库可以切换成自定义语料库的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "劳动防护13.900677652\r\n",
      "劳动防护13.900677652\r\n",
      "生化学13.900677652\r\n",
      "生化学13.900677652\r\n",
      "奥萨贝尔13.900677652\r\n",
      "奥萨贝尔13.900677652\r\n",
      "考察队员13.900677652\r\n",
      "考察队员13.900677652\r\n",
      "岗上11.5027823792\r\n",
      "岗上11.5027823792\r\n"
     ]
    }
   ],
   "source": [
    "!head idf.txt.big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图灵/奠基者/麦席森/1948/成绩/重要/计算机/人工智能/艾伦/逻辑\n"
     ]
    }
   ],
   "source": [
    "jieba.analyse.set_idf_path(\"idf.txt.big\")\n",
    "tags = jieba.analyse.extract_tags(sentences, topK=10)\n",
    "print('/'.join(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关键词提取所使用停止词（Stop Words）文本语料库可以切换成自定义语料库的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\r\n",
      "of\r\n",
      "is\r\n",
      "and\r\n",
      "to\r\n",
      "in\r\n",
      "that\r\n",
      "we\r\n",
      "for\r\n",
      "an\r\n"
     ]
    }
   ],
   "source": [
    "!head stop_words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图灵/奠基者/麦席森/1948/成绩/重要/计算机/人工智能/艾伦/逻辑\n"
     ]
    }
   ],
   "source": [
    "jieba.analyse.set_stop_words(\"stop_words.txt\")\n",
    "jieba.analyse.set_idf_path(\"idf.txt.big\")\n",
    "tags = jieba.analyse.extract_tags(sentences, topK=10)\n",
    "print('/'.join(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关键词一并返回关键词权重值示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag: 图灵\t\t weight: 0.484653\n",
      "tag: 奠基者\t\t weight: 0.323102\n",
      "tag: 麦席森\t\t weight: 0.323102\n",
      "tag: 1948\t\t weight: 0.323102\n",
      "tag: 成绩\t\t weight: 0.323102\n",
      "tag: 重要\t\t weight: 0.323102\n",
      "tag: 计算机\t\t weight: 0.323102\n",
      "tag: 人工智能\t\t weight: 0.323102\n",
      "tag: 艾伦\t\t weight: 0.323102\n",
      "tag: 逻辑\t\t weight: 0.323102\n"
     ]
    }
   ],
   "source": [
    "tags = jieba.analyse.extract_tags(sentences, topK=10, withWeight=True)\n",
    "for tag in tags:\n",
    "    print(\"tag: %s\\t\\t weight: %f\" % (tag[0], tag[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 基于 TextRank 算法的关键词抽取\n",
    "- `jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))` 直接使用，接口相同，注意默认过滤词性。\n",
    "- `jieba.analyse.TextRank()` 新建自定义 TextRank 实例\n",
    "- 算法论文： [TextRank: Bringing Order into Texts](http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)\n",
    "- 基本思想:\n",
    "    - 将待抽取关键词的文本进行分词\n",
    "    - 以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图\n",
    "    - 计算图中节点的PageRank，注意是无向带权图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欧亚 1.01742702152\n",
      "吉林 1.01742702152\n",
      "万元 0.763070266143\n",
      "置业 0.763070266143\n",
      "增资 0.508713510762\n",
      "亿元 0.508713510762\n",
      "实现 0.508713510762\n",
      "在建 0.254356755381\n",
      "房地产 0.254356755381\n",
      "目前 0.254356755381\n"
     ]
    }
   ],
   "source": [
    "s = \"此外，公司拟对全资子公司吉林欧亚置业有限公司增资4.3亿元，增资后，吉林欧亚置业注册资本由7000万元增加到5亿元。吉林欧亚置业主要经营范围为房地产开发及百货零售等业务。目前在建吉林欧亚城市商业综合体项目。2013年，实现营业收入0万元，实现净利润-139.13万元。\"\n",
    "\n",
    "# TF-IDF\n",
    "for x, w in jieba.analyse.extract_tags(s, topK=10, withWeight=True):\n",
    "    print('%s %s' % (x, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吉林 1.0\n",
      "欧亚 0.996689335418\n",
      "置业 0.643436031309\n",
      "实现 0.589860669286\n",
      "收入 0.43677859948\n",
      "增资 0.409990053128\n",
      "子公司 0.356782959477\n",
      "城市 0.349713836674\n",
      "商业 0.34817220716\n",
      "业务 0.309223099262\n"
     ]
    }
   ],
   "source": [
    "# TextRank\n",
    "for x, w in jieba.analyse.textrank(s, topK=10, withWeight=True):\n",
    "    print('%s %s' % (x, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.词性标注\n",
    "- `jieba.posseg.POSTokenizer(tokenizer=None)` 新建自定义分词器，tokenizer 参数可指定内部使用的 jieba.Tokenizer 分词器。`jieba.posseg.dt` 为默认词性标注分词器。\n",
    "- 标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"我爱北京天安门\")\n",
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Tokenize：返回词语在原文的起止位置\n",
    "- 注意，输入参数只接受 unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "# 默认模式\n",
    "result = jieba.tokenize(u'永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限\t\t start: 6 \t\t end:8\n",
      "word 公司\t\t start: 8 \t\t end:10\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "# 搜索模式\n",
    "result = jieba.tokenize(u'永和服装饰品有限公司', mode='search')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
