{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类和标注词汇\n",
    "## 使用词性标注器\n",
    "词性标注器(`part-of-speech tagger` 或 `POS tagger`)处理一个词序列，为每个词附加一个词性标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = nltk.word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text.similar()方法为词w找出所有上下文$w_1ww_2$，然后找出所有出现在相同上下文中的词w'，即$w_1w'w_2$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man time day year car moment world family house country child boy\n",
      "state job way war girl place word work\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text.similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made said put done seen had found left given heard brought got been\n",
      "was set told took in felt that\n"
     ]
    }
   ],
   "source": [
    "text.similar('bought')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in on to of and for with from at by that into as up out down through\n",
      "is all about\n"
     ]
    }
   ],
   "source": [
    "text.similar('over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a his this their its her an that our any all one these my in your no\n",
      "some other and\n"
     ]
    }
   ],
   "source": [
    "text.similar('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标注语料库\n",
    "按照NLTK的约定，已标注的标识符使用一个由标识符和标记组成的元组来表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fly', 'NN')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_token = nltk.tag.str2tuple('fly/NN')\n",
    "tagged_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fly'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_token[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从一个字符串构造一个已标注的标识符的链表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('grand', 'JJ'),\n",
       " ('jury', 'NN'),\n",
       " ('commented', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('a', 'AT'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('other', 'AP'),\n",
       " ('topics', 'NNS'),\n",
       " (',', ','),\n",
       " ('AMONG', 'IN'),\n",
       " ('them', 'PPO'),\n",
       " ('the', 'AT'),\n",
       " ('Atlanta', 'NP'),\n",
       " ('and', 'CC'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('purchasing', 'VBG'),\n",
       " ('departments', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('it', 'PPS'),\n",
       " ('said', 'VBD'),\n",
       " ('``', '``'),\n",
       " ('ARE', 'BER'),\n",
       " ('well', 'QL'),\n",
       " ('operated', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('follow', 'VB'),\n",
       " ('generally', 'RB'),\n",
       " ('accepted', 'VBN'),\n",
       " ('practices', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('inure', 'VB'),\n",
       " ('to', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('best', 'JJT'),\n",
       " ('interest', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('both', 'ABX'),\n",
       " ('governments', 'NNS'),\n",
       " (\"''\", \"''\"),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = '''\n",
    "... The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN\n",
    "... other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC\n",
    "... Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS\n",
    "... said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB\n",
    "... accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT\n",
    "... interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n",
    "... '''\n",
    "\n",
    "[nltk.tag.str2tuple(t) for t in sent.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取已标注的语料库\n",
    "只要语料库包含已标注的文本，NLTK的语料库接口都将有一个tagged_words()方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'now', 'RB'), (u'im', 'PRP'), (u'left', 'VBD'), ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.nps_chat.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Confidence', u'NN'), (u'in', u'IN'), ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.conll2000.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Pierre', u'NNP'), (u'Vinken', u'NNP'), ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.treebank.tagged_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用内置映射到简化的标记集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'The', u'DET'), (u'Fulton', u'NOUN'), ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_words(tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Pierre', u'NOUN'), (u'Vinken', u'NOUN'), ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.treebank.tagged_words(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中文、印地语、葡萄牙语、西班牙语、荷兰语等这些通常含有非ASCII文本，当输出较大的结构如列表时，Python总是以十六进制显示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'\\u4e00', u'Neu'), (u'\\u53cb\\u60c5', u'Nad'), ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.sinica_treebank.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'\\u09ae\\u09b9\\u09bf\\u09b7\\u09c7\\u09b0', u'NN'), (u'\\u09b8\\u09a8\\u09cd\\u09a4\\u09be\\u09a8', u'NN'), ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.indian.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Jersei', u'N'), (u'atinge', u'V'), ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.mac_morpho.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Sao', u'NC'), (u'Paulo', u'VMI'), (u'(', u'Fpa'), ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.conll2002.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'El', u'da0ms0'), (u'Tribunal_Suprem', u'np0000o'), ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.cess_cat.tagged_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简化的词性标记集\n",
    "Table 5-1. Simplified part-of-speech tagset\n",
    "\n",
    "| Tag | Meaning | Examples |\n",
    "| --- | ------- | -------- |\n",
    "| ADJ | adjective | new, good, high, special, big, local|\n",
    "| ADP | adposition | on, of, at, with, by, into, under|\n",
    "| ADV | adverb | really, already, still, early, now|\n",
    "| CONJ | conjunction | and, or, but, if, while, although|\n",
    "| DET | determiner, article | the, a, some, most, every, no, which|\n",
    "| NOUN | noun | year, home, costs, time, Africa|\n",
    "| NUM | numeral | twenty-four, fourth, 1991, 14:24|\n",
    "| PRT | particle | at, on, out, over per, that, up, with|\n",
    "| PRON | pronoun | he, their, her, its, my, I, us|\n",
    "| VERB | verb | is, say, told, given, playing, would|\n",
    "| . | punctuation | marks\t. , ; !|\n",
    "| X | other | ersatz, esprit, dunno, gr8, univeristy|\n",
    "\n",
    "### 名词\n",
    "检查一些已标注的文本，看看哪些词类出现在名词前，频率最高的在最前面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ADV',\n",
       " u'NOUN',\n",
       " u'ADP',\n",
       " u'PRON',\n",
       " u'DET',\n",
       " u'.',\n",
       " u'PRT',\n",
       " u'VERB',\n",
       " u'X',\n",
       " u'NUM',\n",
       " u'CONJ',\n",
       " u'ADJ']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "brown_news_tagged = nltk.corpus.brown.tagged_words(categories='news', tagset='universal')\n",
    "\n",
    "word_tag_pairs = nltk.bigrams(brown_news_tagged)\n",
    "list(nltk.FreqDist(a[1] for (a, b) in word_tag_pairs if b[1] == 'NOUN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "名词出现在限定词和形容词之后。\n",
    "\n",
    "### 动词\n",
    "新闻中最常见的动词是什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'attributes/VBZ',\n",
       " u'negotiated/VBN',\n",
       " u'failed/VBD',\n",
       " u'printed/VBN',\n",
       " u'sticking/VBG',\n",
       " u'close/VB',\n",
       " u'filed/VBN',\n",
       " u'teaches/VBZ',\n",
       " u'chooses/VBZ',\n",
       " u'suffer/VBP',\n",
       " u'agree/VBP',\n",
       " u'buy/VBP',\n",
       " u'called/VBN',\n",
       " u'underline/VB',\n",
       " u'controlling/VBG',\n",
       " u'exhausted/VBN',\n",
       " u'declaring/VBG',\n",
       " u'staid/VBN',\n",
       " u'stretching/VBG',\n",
       " u'packaging/VBG',\n",
       " u'study/VBP',\n",
       " u'mount/VB',\n",
       " u'sparing/VBG',\n",
       " u'guaranteed/VBN',\n",
       " u'confined/VBN',\n",
       " u'gives/VBZ',\n",
       " u'provoke/VB',\n",
       " u'frustrating/VBG',\n",
       " u'oversee/VB',\n",
       " u'suing/VBG']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj = nltk.corpus.treebank.tagged_words()\n",
    "word_tag_fd = nltk.FreqDist(wsj)\n",
    "[word + \"/\" + tag for (word, tag) in word_tag_fd if tag.startswith('V')][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于词汇和标记是成对的，我们可以把词作为条件，标记作为事件，使用条件-事件对的链表初始化一个条件频率分布。这样我们可以看到一个给定词的标记的频率顺序表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'VB', u'NN']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd1 = nltk.ConditionalFreqDist(wsj)\n",
    "cfd1['yield'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'VB', u'VBN', u'NN', u'VBD']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd1['cut'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "颠倒配对顺序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'limited',\n",
       " u'reorganized',\n",
       " u'managed',\n",
       " u'switched',\n",
       " u'caused',\n",
       " u'founded',\n",
       " u'assembled',\n",
       " u'concerned',\n",
       " u'contained',\n",
       " u'Rekindled',\n",
       " u'automated',\n",
       " u'bribed',\n",
       " u'voted',\n",
       " u'issued',\n",
       " u'cluttered',\n",
       " u'disapproved',\n",
       " u'sent',\n",
       " u'returned',\n",
       " u'synchronized',\n",
       " u'puzzled',\n",
       " u'desired',\n",
       " u'engineered',\n",
       " u'headlined',\n",
       " u'centralized',\n",
       " u'advised',\n",
       " u'stabbed',\n",
       " u'continued',\n",
       " u'perceived',\n",
       " u'presented',\n",
       " u'prolonged']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd2 = nltk.ConditionalFreqDist((tag, word) for (word, tag) in wsj)\n",
    "cfd2['VBN'].keys()[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要弄清VBD(过去式)和VBN(过去分词)之间的区别，让我们找到可以同是VBD和VBN的词汇，看看它们周围的文字的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'contributed',\n",
       " u'reported',\n",
       " u'brought',\n",
       " u'plunged',\n",
       " u'welcomed',\n",
       " u'assured',\n",
       " u'threatened',\n",
       " u'needed',\n",
       " u'nominated',\n",
       " u'rolled',\n",
       " u'asked',\n",
       " u'worked',\n",
       " u'climbed',\n",
       " u'damaged',\n",
       " u'had',\n",
       " u'imposed',\n",
       " u'raised',\n",
       " u'resulted',\n",
       " u'invested',\n",
       " u'bribed',\n",
       " u'solved',\n",
       " u'studied',\n",
       " u'opposed',\n",
       " u'believed',\n",
       " u'allowed',\n",
       " u'fueled',\n",
       " u'matched',\n",
       " u'surged',\n",
       " u'turned',\n",
       " u'printed']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in cfd1.conditions() if 'VBD' in cfd1[w] and 'VBN' in cfd1[w]][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'While', u'IN'),\n",
       " (u'program', u'NN'),\n",
       " (u'trades', u'NNS'),\n",
       " (u'swiftly', u'RB'),\n",
       " (u'kicked', u'VBD')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx1 = wsj.index(('kicked', 'VBD'))\n",
    "wsj[idx1-4:idx1+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'head', u'NN'),\n",
       " (u'of', u'IN'),\n",
       " (u'state', u'NN'),\n",
       " (u'has', u'VBZ'),\n",
       " (u'kicked', u'VBN')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2 = wsj.index(('kicked', 'VBN'))\n",
    "wsj[idx2-4:idx2+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 未简化的标记\n",
    "找出最频繁的名词标记的程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findtags(tag_prefix, tagged_text):\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
    "                                  if tag.startswith(tag_prefix))\n",
    "    return dict((tag, cfd[tag].keys()[:5]) for tag in cfd.conditions())\n",
    "\n",
    "tagdict = findtags('NN', nltk.corpus.brown.tagged_words(categories='news'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN [u'inning', u'pardon', u'sunbonnet', u'temperament', u'hitch']\n",
      "NN$ [u\"junior's\", u\"player's\", u\"wife's\", u\"layman's\", u\"coach's\"]\n",
      "NN$-HL [u\"Golf's\", u\"Navy's\"]\n",
      "NN$-TL [u\"House's\", u\"Art's\", u\"University's\", u\"U.'s\", u\"Department's\"]\n",
      "NN-HL [u'son', u'help', u'show', u'lack', u'rest']\n",
      "NN-NC [u'eva', u'ova', u'aya']\n",
      "NN-TL [u'Communisn', u'Communism', u'Secretary-General', u'Monthly', u'Self']\n",
      "NN-TL-HL [u'City', u'Commissioner', u'Grove', u'House', u'Oak']\n",
      "NNS [u'wetlands', u'hats', u'facilities', u'woods', u'$12.50']\n",
      "NNS$ [u\"steelmakers'\", u\"taxpayers'\", u\"teammates'\", u\"bishops'\", u\"owners'\"]\n",
      "NNS$-HL [u\"Dealers'\", u\"Idols'\"]\n",
      "NNS$-TL [u\"Officers'\", u\"States'\", u\"Bombers'\", u\"Falcons'\", u\"Princes'\"]\n",
      "NNS-HL [u'years', u'idols', u'Creations', u'thanks', u'centers']\n",
      "NNS-TL [u'Gables', u'Broncos', u'Hills', u'Workers', u'Ministers']\n",
      "NNS-TL-HL [u'Nations']\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(tagdict):\n",
    "    print tag, tagdict[tag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 探索已标注的语料库\n",
    "观察跟在often后面的词汇。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u',',\n",
       " u'.',\n",
       " u'accomplished',\n",
       " u'analytically',\n",
       " u'appear',\n",
       " u'apt',\n",
       " u'associated',\n",
       " u'assuming',\n",
       " u'became',\n",
       " u'become',\n",
       " u'been',\n",
       " u'began',\n",
       " u'call',\n",
       " u'called',\n",
       " u'carefully',\n",
       " u'chose',\n",
       " u'classified',\n",
       " u'colorful',\n",
       " u'composed',\n",
       " u'contain',\n",
       " u'differed',\n",
       " u'difficult',\n",
       " u'encountered',\n",
       " u'enough',\n",
       " u'equate',\n",
       " u'extremely',\n",
       " u'found',\n",
       " u'happens',\n",
       " u'have',\n",
       " u'ignored',\n",
       " u'in',\n",
       " u'involved',\n",
       " u'more',\n",
       " u'needed',\n",
       " u'nightly',\n",
       " u'observed',\n",
       " u'of',\n",
       " u'on',\n",
       " u'out',\n",
       " u'quite',\n",
       " u'represent',\n",
       " u'responsible',\n",
       " u'revamped',\n",
       " u'seclude',\n",
       " u'set',\n",
       " u'shortened',\n",
       " u'sing',\n",
       " u'sounded',\n",
       " u'stated',\n",
       " u'still',\n",
       " u'sung',\n",
       " u'supported',\n",
       " u'than',\n",
       " u'to',\n",
       " u'when',\n",
       " u'work']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_learned_text = brown.words(categories='learned')\n",
    "sorted(set(b for (a, b) in nltk.bigrams(brown_learned_text) if a == 'often'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看跟随词的词性标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBN  VB VBD  JJ  IN  RB   ,  CS  QL WRB  TO VBG BEN  HV QLP  AP  RP   . VBZ \n",
      " 15  10   8   5   4   3   3   3   3   1   1   1   1   1   1   1   1   1   1 \n"
     ]
    }
   ],
   "source": [
    "brown_lrnd_tagged = brown.tagged_words(categories='learned')\n",
    "tags = [b[1] for (a, b) in nltk.bigrams(brown_lrnd_tagged) if a[0] == 'often']\n",
    "fd = nltk.FreqDist(tags)\n",
    "fd.tabulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "often后面最高频率的词性是动词。名词从来没有在这个位置出现（在特定的语料中）。\n",
    "\n",
    "使用POS标记寻找三词短语。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined to achieve\n",
      "continue to place\n",
      "serve to protect\n",
      "wanted to wait\n",
      "allowed to place\n",
      "expected to become\n",
      "expected to approve\n",
      "expected to make\n",
      "intends to make\n",
      "seek to set\n",
      "like to see\n",
      "designed to provide\n",
      "get to hear\n",
      "expects to tell\n",
      "expected to give\n",
      "prefer to pay\n",
      "required to obtain\n",
      "permitted to teach\n",
      "designed to reduce\n",
      "Asked to elaborate\n",
      "got to go\n",
      "raised to pay\n",
      "scheduled to go\n",
      "cut to meet\n",
      "needed to meet\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "def process(sentence):\n",
    "    for (w1,t1), (w2,t2), (w3,t3) in nltk.trigrams(sentence):\n",
    "        if (t1.startswith('V') and t2 == 'TO' and t3.startswith('V')):\n",
    "            print w1, w2, w3\n",
    "\n",
    "for tagged_sent in brown.tagged_sents()[:300]:\n",
    "    process(tagged_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各自的上下文可以帮助我们弄清楚标记之间的区别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second OD-TL OD RB NN QL\n",
      "place NP VB NN-TL NN\n",
      "fair JJ-HL JJ-TL NN-TL NN JJ\n",
      "best VB JJT NP-TL RBT JJT-HL\n",
      "right RB JJ NN QL\n",
      "for CS IN-TL IN-HL RB IN\n",
      "ballet FW-NN NN-TL NN FW-NN-TL\n",
      "red NP NN-TL JJ-TL JJ\n",
      "open VB NN NN-TL RB JJ\n",
      "act NN-HL VB NN-TL NN\n",
      "as CS CS-HL QL IN\n",
      "to TO-TL IN-TL TO IN-HL TO-HL IN NPS\n",
      "past AP JJ NN IN\n",
      "more AP RBR AP-HL QL\n",
      "major NP NN-TL NN JJ\n",
      "plan NN-HL VB NN-TL NN\n",
      "gold NN-TL JJ-TL NN JJ\n",
      "set VB VBN-HL VBN NN VBD\n",
      "read NP VB VBN VBD\n",
      "by IN-HL IN-TL RB IN\n",
      "high JJ-HL RB JJ-TL NN JJ\n",
      "lay NP VB JJ VBD\n",
      "green NP JJ-TL NN JJ\n",
      "post NP VB NN-TL NN\n",
      "brown NP NN JJ NP-TL\n",
      "cost NN-HL VB NN VBD\n",
      "congolese NP JJ-TL NPS JJ\n",
      "last AP VB AP-HL NN AP-TL\n",
      "increase NN-HL VB VB-HL NN\n",
      "that CS DT WPO QL WPS\n",
      "only AP JJ RB QL\n",
      "3 CD-HL CD OD OD-TL CD-TL\n",
      "a FW-IN AT-HL AT NN AT-TL\n",
      "help NN-HL VB VB-HL NN\n",
      "held VBN-HL VBD-HL VBN VBD\n",
      "issue NN-HL VB VB-HL NN\n",
      "st. NP NP-HL NN-TL NP-TL\n",
      "close VB RB JJ NN\n",
      "grant NP VB VB-HL NN\n",
      "march NP NP-HL NN-TL VB NN\n",
      "police NNS-HL NNS NN NNS-TL\n",
      "home NN NN-HL NN-TL NP NR NR-HL\n",
      "force VB NN-TL NN FW-NN-TL\n",
      "even VB JJ QL RB\n",
      "met NP NP-HL VBN VBD\n",
      "better JJR-TL VB QL RBR JJR\n",
      "near RB-HL QL JJ RB IN\n",
      "in IN-TL IN-HL RP IN\n",
      "left NR VBN JJ VBD\n",
      "down RP NP-TL RP-HL IN\n",
      "round VB NN-TL JJ NN\n",
      "french NP JJ-HL JJ-TL NPS JJ\n",
      "first RB-HL OD-TL OD RB OD-HL\n",
      "little NP AP JJ-TL QL JJ\n",
      "reading NN-HL NP VBG NN\n",
      "field NP VB NN-TL NN\n",
      "good JJ-HL RB JJ-TL NN JJ\n",
      "house VB NN NN-HL NN-TL NP-TL-HL NP NN-TL-HL\n",
      "most AP RBT QL QL-TL\n",
      "fine RB JJ-TL JJ NN\n",
      "point NN-HL VB NN-TL NN\n",
      "cut NN-HL VB VBN NN VBD\n",
      "back RB-HL VB RB-TL NN RB\n",
      "chief NN-TL JJS NN JJS-TL\n",
      "beat VB NN-TL-HL NN VBD\n",
      "swim NP VB NP-HL NN\n",
      "general NN-TL JJ-TL NN JJ\n",
      "like CS VB VB-HL JJ IN\n",
      "works VBZ NNS-HL NNS NNS-TL\n",
      "must MD MD-HL NN MD-TL\n",
      "end NN-HL VB NN-TL NN\n",
      "report NN-TL VB VB-HL NN\n",
      "mother NN-HL VB NN-TL NN\n",
      "no AT-HL AT RB AT-TL\n",
      "cook NP VB NN NP-TL\n",
      "white NP NN-TL JJ-TL NN JJ\n",
      "case NP NN-HL NP-TL NN\n",
      "on IN-TL RP IN-HL IN\n",
      "hill NN-HL NP NN-TL NN\n",
      "hit NN-HL VB VBN NN VBD\n",
      "out PP$ RP RP-HL IN\n",
      "present VB NN RB JJ\n",
      "half NN RB ABN QL\n"
     ]
    }
   ],
   "source": [
    "brown_news_tagged = brown.tagged_words(categories='news')\n",
    "data = nltk.ConditionalFreqDist((word.lower(), tag)\n",
    "                                for (word, tag) in brown_news_tagged)\n",
    "for word in data.conditions():\n",
    "    if len(data[word]) > 3:\n",
    "        tags = data[word].keys()\n",
    "        print word, ' '.join(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 默认标注器\n",
    "用最有可能的标记标注每个词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'NN'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
    "nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('green', 'NN'),\n",
       " ('eggs', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('ham', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('them', 'NN'),\n",
       " ('Sam', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('am', 'NN'),\n",
       " ('!', 'NN')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'I do not like green eggs and ham, I do not like them Sam I am!'\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确率只有八分之一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13089484257215028"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则表达式标注器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),               # gerunds\n",
    "    (r'.*ed$', 'VBD'),                # simple past\n",
    "    (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),               # modals\n",
    "    (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "    (r'.*s$', 'NNS'),                 # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "    (r'.*', 'NN')                     # nouns (default)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "约五分之一的正确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'``', 'NN'),\n",
       " (u'Only', 'NN'),\n",
       " (u'a', 'NN'),\n",
       " (u'relative', 'NN'),\n",
       " (u'handful', 'NN'),\n",
       " (u'of', 'NN'),\n",
       " (u'such', 'NN'),\n",
       " (u'reports', 'NNS'),\n",
       " (u'was', 'NNS'),\n",
       " (u'received', 'VBD'),\n",
       " (u\"''\", 'NN'),\n",
       " (u',', 'NN'),\n",
       " (u'the', 'NN'),\n",
       " (u'jury', 'NN'),\n",
       " (u'said', 'NN'),\n",
       " (u',', 'NN'),\n",
       " (u'``', 'NN'),\n",
       " (u'considering', 'VBG'),\n",
       " (u'the', 'NN'),\n",
       " (u'widespread', 'NN'),\n",
       " (u'interest', 'NN'),\n",
       " (u'in', 'NN'),\n",
       " (u'the', 'NN'),\n",
       " (u'election', 'NN'),\n",
       " (u',', 'NN'),\n",
       " (u'the', 'NN'),\n",
       " (u'number', 'NN'),\n",
       " (u'of', 'NN'),\n",
       " (u'voters', 'NNS'),\n",
       " (u'and', 'NN'),\n",
       " (u'the', 'NN'),\n",
       " (u'size', 'NN'),\n",
       " (u'of', 'NN'),\n",
       " (u'this', 'NNS'),\n",
       " (u'city', 'NN'),\n",
       " (u\"''\", 'NN'),\n",
       " (u'.', 'NN')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "regexp_tagger.tag(brown_sents[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20326391789486245"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查询标注器\n",
    "找出100个最频繁的词，存储它们最有可能的标记。然后使用这个信息作为“查找标注器”(NLTK UnigramTagger)的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005171350717027666"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(brown.words(categories='news'))\n",
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
    "most_freq_words = fd.keys()[:100]\n",
    "likely_tags = dict((word, cfd[word].max()) for word in most_freq_words)\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags)\n",
    "baseline_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确率近一半。看看它在一些未标注文本上如何运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'``', None),\n",
       " (u'Only', None),\n",
       " (u'a', None),\n",
       " (u'relative', None),\n",
       " (u'handful', None),\n",
       " (u'of', None),\n",
       " (u'such', None),\n",
       " (u'reports', u'NNS'),\n",
       " (u'was', None),\n",
       " (u'received', None),\n",
       " (u\"''\", None),\n",
       " (u',', None),\n",
       " (u'the', None),\n",
       " (u'jury', None),\n",
       " (u'said', None),\n",
       " (u',', None),\n",
       " (u'``', None),\n",
       " (u'considering', None),\n",
       " (u'the', None),\n",
       " (u'widespread', None),\n",
       " (u'interest', None),\n",
       " (u'in', None),\n",
       " (u'the', None),\n",
       " (u'election', None),\n",
       " (u',', None),\n",
       " (u'the', None),\n",
       " (u'number', None),\n",
       " (u'of', None),\n",
       " (u'voters', None),\n",
       " (u'and', None),\n",
       " (u'the', None),\n",
       " (u'size', None),\n",
       " (u'of', None),\n",
       " (u'this', None),\n",
       " (u'city', None),\n",
       " (u\"''\", None),\n",
       " (u'.', None)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = brown.sents(categories='news')[3]\n",
    "baseline_tagger.tag(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "许多词被分配了None标签，因为它们不在100个最频繁的词之中。在这些情况下分配默认标记NN。换句话说，我们要先使用查找表，如果不能指定标记就使用默认标注器，这个过程叫做`backoff`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags,\n",
    "                                     backoff=nltk.DefaultTagger('NN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查找标注器的性能，使用不同大小的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEZCAYAAAC5AHPcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecVNX9//HXG8SGitgFIiIgGmJX5GvdiBrUWCMBa9DY\nfolomooKskiMYkxiN6IoigVr1CT2sliJKIgNFBGRZsEGIiKyn98f5yxcxt1ltty5M7uf5+Oxj71t\n7v3MzJ35zD3n3HNkZjjnnHN11SLrAJxzzpUmTyDOOefqxROIc865evEE4pxzrl48gTjnnKsXTyDO\nOefqxRPISkh6RtKJWcfRXEhqJ+kFSV9JGpZ1PMVE0lOS+tSy/k5J5xUypnxJ6iVpYtZx5EvSapIq\nJbXLY9ufSZpaz+OUS7qyPo8tBk0qgUiaLmmfrOOoK0kPS1ogab6k7yQtjtPzJV2bdXy1iR+epTHW\nryS9JemYBuzyN8B0M2tjZoMbK86mwMx6mdk9AJJOlfREffYjqXU833pWs+46Sbc2NNZcZvaUme3Q\n2PsFkDQuftl3zVn+SFzeo567rstNcjVuK+lISZMkfSnpY0mPVyUmMys3szPqGV/mmlQCKVVmdqCZ\nrW1m6wC3A8PNbJ3495us46siqWUNq6bFWNsA5cAoSZ3quG9JagF0BN5u5PiaqnrdBWxmC4F7geOT\nyyW1AvoAo+q6z4xfewPeIfF8JG0CbAN80YD9qoFxIWlr4AbgN2a2LtAZGAFUNnTfxaDZJBBJJ0ua\nKmmepAckbZpYt5uklyV9Iel/kv6vhn1sGn9J/DHOr3DFI2mIpNFxumP89XOypNnx74/1jH2DeJXy\nSSL+jRPruySKfR6W9E9JNyTWnyTpw/jr5yxJcyXtFte1kDRY0rS4/9GS1onruklaUvV44L8rizX+\nQl4EbB33sWf8hfiFpFeqjhvXvSRpqKRxwELgCaAvcEG8otld0uqSrpE0Jz6HS6u+rKqKDiQNkvQR\ncG1i2fmSPpU0U9KBkg6V9F5c9odEDLsl4psl6e8xkSWLMU6Oj/1M0t9z3pvfSJoc450kqXtc3iG+\nT5/Gx55aw3u7laSPE/OjJc1IzN8t6ZTE63W0pO2By4EyhSuJOYldbijp0RjPc5J+VMNbdSvwy5g0\nqhwMfGNmT8fjDZb0ftzX65IOTMR1qkKR2tWSPgPOi+df58Q2HSQtlLSOcop54jn4O0lvxNd+tKRV\nEusHSfoovucna+XFSbcBySvfY4C7gKWJfdZ4LsX151cdEziWRIKOj708Pm6OpCtzXrua7AhMNrMX\nAMzsazO718w+ivu9WNKIOH2DlpdELJD0vaSzE6/lSs+ngjOzJvMHTAf2qWb5PsCnwHZAK+BKYGxc\n1xb4HDiakFD7xfm2cf0zwInA5oRfOb+u6XjAEODWON2R8CvjdmB14CfAJ9XFlxPrzcCFOcs2Iny4\nVwXWBv4F3JFYPwG4EFgF2Bv4GhgR1+0AfAXsEp/7FcB3wG5x/TnAWGDjuP+bgJvium7xOYyIz2G1\nauL9GfBunFZ8/b4FNouv2Tzgp3F97/gatInzLwHvAV2AlvH1vxM4L7H/S2N8bYENgZeBcxPHXhJf\n91WA1RLL/hT3dzrwMXBLfA7bExLcpnEfOwM7xelOwLvAKXF+tfj87wVax+fzBbBXXH9cPAe2jfNd\ngXbxuK/HGFrG5/cBsGcN7/lcYOvEOTUN6BjnPwK2TLxeR8fpU4HHc/ZzZ9x+u3jce6rey1o+L0ck\n5u8H/pKY7wNsFKePAeYD6yWO/x3hs6H42t4IDEk8/mzgrtzzJPGcnwM2ANYHpgLHx3WHAR/G120N\nlieCdjU8j5cIn98KYO+47LX4OnwK9MjjXDoMmBnfwzXje77smMB1wN2Ez9/awCPA4OqeW05s3Qjn\n26WEz+aaOesvJn5Wc5bvQjhvt6rr+VTQ79ysA2jUJ1NzArkRuCQx3xpYTPiSOxYYl7P9i4mT+Rng\nb3Hfv6zteFSfQLom1g8HbljJc/hBAqlmm57A7Di9JeHXe6vE+ntYnkAuAkYm1q0dPxhVCeR94P8S\n6zsBC+N0t7jtxrXE8jPge0LSnQe8AhwW110AXJ+zfQXQJ06/BAzMWZ+bQGYRvxTi/CHA24ljLwBa\n5sTzRWJ+g/g+/CSx7E1g/xqezznA7XG6KoHskFj/IHBG4rmcVM0+9gLeyVlWDlxTwzHvBk6L58wk\nwtXF8YQvj7mJ7fJJIFcm5g8HJtTy3g0DHozT6xMSf7datp8M7Jc4/pSc9XsDUxPzrwMHJd6X3ARy\neGL+CuDvcfp24pdznO9OfgnkRMIPoO2ASXFdMoHUdi7dDlyQWLdN1TEJX9qLiT864vqynPOw2gQS\n1+9G+Ex+Qvis3kD8MUY1CQTYlJBAD67P+VTIv2WXjE1cO+DVqhkzWyjpc6B9XDcjZ/sZcV2Vowm/\nlO+r43GNcNIm9/uTOu4DSWsRPmD7Am1Y/osPwsn2qZktSTxkJrBWnF7h+ZnZAklfJbb9EfCwJKs6\nXDzmenG+0sw+pnbvm9mW1SzvCByl5S2HRLhS2DSxzcyV7HsTwoepSu5785GZLV3xIXyamF4U/3+S\ns2wtWFZG/TdCUcMahC+LF3L2l3z+37D8tf0RIQHn6gh0iucYhOfdglBEV52xwE8JXy4V8e+QGM+z\nNTymJh/VEGt1bgXekLQ+oehwkpm9U7VS0q+BMwjPU4QfXhskHr/Ce2dmYyW1lLQrIRltAjxay/Fz\nX9f143Q7VnytZpJffcS9wF8IX/bVNQSo7VxqBzyZs06Jda2At6RlYbQgXIGtlJm9SPhRSnxt7iFc\nnf2glaGkVQnfM9eb2b/j4rqeTwXTXOpA5hDeBCC0QiGcrLPjus1ztt8srqtSTvh1facSZxDhA79m\nYn6TnP2I8OFL7ncOdTeQcKLvZKEibn+Wn9xzCeXeyfLY5DHnAh2WBRTqN9ok1s8iXEWtF//amllr\nM6s6WY36m0m44krue20zSzZbXNn+55J47+J08r3JJ77atrmB8OOik4VGAMPIv/J0JqFStLrlk3Oe\ndxszO7KG/Ywl/HrfM04/R/jVuVecr05D3pewA7OphCvGowlX4rdUrVNo0XQl4QprPTNrSyhaS742\n1cVwK6Fo7zhgTDXJPR8rnLOEz81Kn6+ZzWd5kfNt1WzyETWfS3NZ8XPTMXHMuYRi0c6J93RdM9so\nj+eSG+P/CFexNf2Q/Ccwy8wuSiyr6/lUME0xgawaKz+r/loSLu1PkLStpNUIv1LGmdmHwMNAV0n9\n4q+nvoQK4H8n9rmEUB7cGhidSCKvAf0krSJpZ6C6N3SwpDVi5eoJwJh6PKe1Cb/Q5kvaABhUtcLM\n3iXUzQyKcexFqGuocjfwC0k7xSRzIYmKReB6YLikDgCSNpL088T6hrREuQXoI2kfhcr6NeJ0XT54\nY4AhktaLjzsPGF3HOGp7DmsDX5nZovgenVyH/d4IDJS0LYQv3VjR+3ycPzOeg6tI2kZStc1YzexN\nwpVPH+BZM/uM8H4fRM0J5GPgR8mK53q6FfgDoa7szsTytQjnybwY/2mEsveVGQ38klAXVt/mwHcD\nJyk0DmkNnF+Hx/6RUExV3VXzndR8LlUds2u84l/WhNzMvicUjV0Zr9aQ9CNJ+64sGEllkk6In1vi\nOXYQodgtd9szCVfCv8pZVafzqZCaYgL5L+HDtyj+H2JmTxFOiPsJvzg6EU5w4i/tnxMqqObF/weZ\nWVXzP4vbfQ8cQajQHhnXDSZ8qD4n1H/cXk08YwnFX08Al8ZYalPdL63LCJV+nxGKNHJbQ/UF9otx\nDCR8GBbHuF8DzgIeIFxtzCZUqi+Oj700xvZ0LNp6nvBlUls8eTGz6cAvgKGE13Y6oUik6ryrbt+5\nyy4gNOt9i9BY4Dngr3UNpZb53wMnS5oPXMUPE3yNjzWz24C/A/fGx98DrBvPlQMJZd8zCF/21xJ+\ngNTkOUK91rw4Pxb4zszeqiGWRwkVqZ/EVkP1dRfhnP5v4pzHzCYSfg2/SjhnOgLjV7YzM5tGaIiw\nwMxeqW3TWvbxAOEz9gIwheXFeItrekjisXPMbFwNx6nxXIrHHBGXvc0Pi95+Ryg9eEXSl4QfntVd\nfeb6gvDD8s14jjxISFpXVLNtP0K948eJ1li/q+f5VBCKFTLp7FwaSfhy/tjMtq1hmyuBAwjFQf3j\nF17Jk9SRUD7eyswK2uZb0gPAS2Y2vJp16xISzaZ51G04V2eSbiNUMP+lkfa3PfCima250o1dQaV9\nBXIzoYVCtSQdQChX7Epo1fHPlOMptAbfiJTXQaQeCvedSNLBhNf8wcT6gxXasa8F/IOQXDx5uEYn\nqQvhR+PNDdzP4ZJaxaKfiwlN112RSTWBmNnz1H4n6KHEctJYudRGiRvkmoD0Lu9W1IFQ9DSf0FT4\nBDObkljfh1CB+CGhBdSxBYrLNSOShhOKvIaa2dwG7m4AoTXdZEKR65kN3J9LQapFWLCsKOff1RVh\nSfo3cHFs5oakJ4GzzWxCqkE555xrsKZYie6cc64Asr6RcDYrtr3uwIpt/JdJ3OjmnHOuDswslfrY\nQlyBiJorkx8i9qCp0LX0l7VV7mZ9237u35AhQzKPoVTi8pg8puYQVzHGlKZUr0Ak3UHoM2b92FZ9\nCKHDPjOzEWb2sEJPqe8RmvGekGY8zjnnGk+qCcTMjs5jm9PTjME551w6vBK9AcrKyrIOoVrFGJfH\nlB+PKX/FGFcxxpSm1JvxNhZJViqxOudcsZCElXAlunPOuSbIE4hzzrl68QTinHOuXjyBOOecqxdP\nIM455+rFE4hzzrl68QTinHOuXrLuTNE555q06dNnMHjwKGbPrqR9+xYMG9afTp06Zh1Wo/AbCZ1z\nLiXTp89gv/2uYtq0oYQhzBfSufMQnnhiQMGSiN9I6JxzJWjw4FGJ5AHQmmnThjJ48KgMo2o8nkCc\ncy4F8+bBs89Wsjx5VGnNnDmVWYTU6DyBOOdcI5o/H8rLoVs3WH31FoSRKpIW0q5d0/jqbRrPwjnn\nMrZoEVx2GXTpAu+/D+PHw2OP9adz5yEsTyKhDmTYsP7ZBdqIvBLdOeca4Lvv4KabYNgw6NkTLrwQ\nundfvr6qFdacOZW0a1f4VlhpVqKnnkAk9QYuJ1ztjDSz4Tnr1wVuAjoDi4ATzeztavbjCcQ5VzSW\nLoU77gjFVV26wJ//DLvsknVUP5RmAkl7SNsWwNVAL2AOMF7Sg2Y2JbHZecBEMztCUjfgGmDfNONy\nzrn6MoMHHoBBg2DddWHkSGhm40gtk/aNhD2AqWY2A0DSGOBQIJlAfgxcDGBm70jaXNKGZvZpyrE5\n51zezODJJ+H880Ox1aWXwoEHglL5bV8a0k4g7YGZiflZhKSSNAk4AnhBUg9gM6AD4AnEOVcUXnwx\nJI45c0Jdx5FHQgtvglQUXZlcAlwhaQLwBjARWFrdhuXl5cumy8rKmt34w865wpo0KRRVTZoU6jqO\nPx5WKYZvzVpUVFRQUVFRkGOlWokuqSdQbma94/xAwHIr0nMeMx3Yxsy+zlnulejOuYJ4910YMgSe\neQbOOw9OOQVWXz3rqOqnlLsyGQ90kdRR0qpAP+Ch5AaS2khqFadPBsbmJg/nnCuEmTPh5JNht91g\nm23gvffgjDNKN3mkLdWLMTNbKul04HGWN+OdLOnUsNpGAFsDt0iqBN4Cfp1mTM45l+uTT+Avf4HR\no+HUU2HqVGjbNuuoip/fSOica7a+/DLcPX7ddXDMMaG4apNNso6qcZVyEZZzzhWdhQvhkkuga1eY\nOxcmTIArr2x6ySNtnkCcc83G4sVw9dXhzvGJE+G558KNgB2bxvhOBVfkDdKcc67hvv8ebrstNMXt\n3h0efhh22CHrqEqfJxDnXJNVWQn33QcXXAAbbhiSyB57ZB1V0+EJxDnX5JjBo4+Gu8cluPxy2H//\n5t3tSBo8gTjnmpTnngutqT77LHQ7csQRnjjS4gnEOdckvPpq6HZkyhQYOjQ0y23ZMuuomjZvheWc\nK2mTJ0OfPnDwweHvnXdCn1WePNLnCcQ5V5I++AD694e99goDOb33HvzmN7DqqllH1nx4AnHOlZS5\nc+H002GnnWCzzULiOPtsWHPNrCNrfjyBOOdKwuefw8CB8JOfwGqrhbqOCy+ENm2yjqz58gTinCtq\nCxaE8ca33BK++CKMzfG3v4X7Oly2PIE454rSt9+G+ze6dg0V5S+9BNdfDx06ZB2Zq+LNeJ1zRWXJ\nEhg1KhRP7bgjPP44bLtt1lG56ngCcc4VhcpKuOuu0O3IZpvBPfdAz55ZR+Vq4wnEOZcpM/jPf8JN\ngKuvDv/8J/TqlXVULh+p14FI6i1piqR3JZ1Tzfr1JT0i6TVJb0jqn3ZMzrni8MwzYfjY884LRVbj\nxnnyKCWpjkgoqQXwLtALmEMYI72fmU1JbDMEWN3MzpW0AfAOsLGZfZ+zLx+R0Lkm4uWXQ0eH06eH\nxNG3r985npZSHpGwBzDVzGaY2RJgDHBozjYfAWvH6bWBz3KTh3OuaXjzTTj88NDBYZ8+oXXV0Ud7\n8ihVaSeQ9sDMxPysuCzpBqC7pDnAJODMlGNyzhXYtGlw7LGheGrPPWHqVDjlFGjVKuvIXEMUQyX6\nucAkM/uppM7AE5K2NbOvczcsLy9fNl1WVkZZWVnBgnTO1d3s2aFL9XvugTPPhGuvhXXWyTqqpq2i\nooKKioqCHCvtOpCeQLmZ9Y7zAwEzs+GJbR4GLjKzF+L8U8A5ZvZKzr68DsS5EjFvHlxyCdx8M/z6\n13DOObD++llH1TyVch3IeKCLpI6SVgX6AQ/lbDMZ2BdA0sbAlsD7KcflnEvB/Plh3PFu3WDRInjj\nDbj0Uk8eTVWqRVhmtlTS6cDjhGQ10swmSzo1rLYRwMXAzZImAQLONrPP04zLOde4Fi2Ca64JyeKA\nA2D8eNhii6yjcmlLtQirMXkRlnPF57vvYOTI0Nlhz56hSW737llH5ZLSLMIqhkp051yJWboU7rgD\nhgwJnR0+8EAY1Mk1L55AnHN5MwvJYtAgWHfdUEm+995ZR+Wy4gnEObdSZvDkk6HLkSVL4K9/DXUd\nSqVgxJUKTyDOuVq9+GLodmTOnHBPx5FHQgsfScjhA0o552rw2mvw85/DUUfBccfBW2/BL3/pycMt\n56eCc24F774L/fqFIqr99w/zJ54Iq3h5hcvhCcQ5B8CHH8JJJ8Huu8N224X+qs44A1ZbLevIXLHy\nBOJcM/fJJ/C738EOO8DGG4crjnPPhbXWyjoyV+w8gTjXTH35ZWiOu/XWoZXV22/DRRdB27ZZR+ZK\nhScQ55qZhQtDR4ddu8LcuTBhAlxxRbj6cK4uPIE410wsXgxXXQVdusDEifDcc6Ebko4ds47MlSpv\nV+FcE/f99zB6NAwdGvqpevjhUN/hXEN5AnGuiaqshPvug8GDQ/HU7beHFlbONRZPIM41MWbw6KPh\n7vEWLeDKK2G//bzbEdf4PIE414Q891zor+qzz0IX64cf7onDpccTiHNNwKuvhia5U6aEuo5jjoGW\nLbOOyjV1qbfCktRb0hRJ70o6p5r1f5I0UdIESW9I+l7SumnH5VxTMHly6NzwkEPg4IPhnXfg+OM9\nebjCSHVEQkktgHeBXsAcwhjp/cxsSg3b/xz4nZntW806H5HQuWj69HCl8fDDcNZZ8NvfwpprZh2V\nK0ZpjkiY9hVID2Cqmc0wsyXAGODQWrY/Crgz5ZicK1lz58Lpp8POO4f7N6ZODQnEk4fLQtoJpD0w\nMzE/Ky77AUlrAL2B+1KOybmS8/nnMHAg/OQnoXPDqrqONm2yjsw1Z8VUiX4w8LyZfVnTBuXl5cum\ny8rKKCsrSz8q5zK0YEHoZuTyy+EXv4BJk6BDh6yjcsWsoqKCioqKghwr7TqQnkC5mfWO8wMBM7Ph\n1Wx7P3C3mY2pYV9eB+KajW+/heuug+HDoVevcLXRpUvWUblSVMp1IOOBLpI6SloV6Ac8lLuRpDbA\n3sCDKcfjXFFbsgRuuCF0dDh2LDzxRLiD3JOHK0apFmGZ2VJJpwOPE5LVSDObLOnUsNpGxE0PAx4z\ns0VpxuNcsaqshLvuggsuCJXj99wDPXtmHZVztUu1CKsxeRGWa4rM4D//CTcBrrFGGI+jV6+so3JN\nSZpFWMVUie5cs/LMM6Hbka+/Donj4IO92xFXWjyBOFdgL78cOjqcPh0uvBD69vU7x11p8gGlnCuQ\nN96Aww6DI46APn1CNyRHH+3Jw5WuvBOIpDUkdUszGOeaomnT4NhjYd99Ya+9wt3jp5wCrVplHZlz\nDZNXApF0MPAa8Gic317SD5rjOueWmz0bTjsNdt0VunWD996DP/whVJY71xTkewVSTujX6ksAM3sN\n6JRSTM6VtHnz4E9/gm23DV2NvPNOGBVw7bWzjsy5xpVvAlliZl/lLPM2tc4lfPUVDBkSrjYWLQp1\nHsOHw/rrZx2Zc+nIN4G8JelooKWkrpKuAl5MMS7nSsY338Bf/xruHv/gAxg/Hq65Btq1yzoy59KV\nbwIZAHQHFgN3AF8Bv0srKOdKwXffhf6qunaFcePCfR233AJbbJF1ZM4Vht+J7lwdLV0Kd9wRiqu2\n3DKMPb7zzllH5Vz1Mu9MUdITyWFmJbWV9FgaATlXrMzgX/8KlePXXw833wyPPurJwzVf+d6JvkFy\nnA4z+0LSRinF5FxRMQu94p5/Pnz/fajvOOAA73bEuXwTSKWkzczsQwBJHfFWWK4ZePHF0F/V3Lkw\nbBgceSS08P4bnAPyTyDnA89LGgsI2BM4JbWonCug6dNnMHjwKGbPrqR9+xYMG9afr77qyKBBoSlu\neTkcdxys4j3HObeCvCvRJW0AVI1QMM7M5qUWVfXH90p01+imT5/BfvtdxbRpQ4HWwEJatx7CGmsM\n4IILOnLKKWEMcudKVeaV6NFqwOfAfODHkvbK50GSekuaIuldSefUsE2ZpImS3pT0TB1icq5BBg8e\nlUgeAK1ZuHAovXqNYsAATx7O1Savi3JJw4G+wFtAZVxswLMreVwL4GqgFzAHGC/pQTObktimDXAN\nsL+ZzY5XOs4VxOzZlSxPHlVa88knldVt7pxLyLdU9zCgm5ktruP+ewBTzWwGgKQxwKHAlMQ2RwP3\nmdlsgEIXjbnma+lS+PjjFsBCVkwiC2nXzmvKnVuZfD8l7wP16Xy6PTAzMT8rLkvaElhP0jOSxks6\nrh7Hca5OvvgCfv5zaNOmP5tvPoSQRAAW0rnzEIYN659dcM6ViHyvQL4BXpP0FKE7EwDM7IxGimFH\nYB/Cz8CXJL1kZu81wr6d+4G33goDOx10EFx2WUdmzhzA4MGXMWdOJe3atWDYsAF06tQx6zCdK3r5\nJpCH4l9dzQY2S8x3iMuSZgHzzOxb4FtJzwLbAT9IIOXl5cumy8rKKCsrq0dIrjl74AE4+WS47DL4\n1a/Csk6dOnLbbUOyDcy5RlJRUUFFRUVBjpVqX1iSWgLvECrR5wIvA0eZ2eTENlsBVwG9CS29/gf0\nNbO3c/blzXhdvVVWhvHHR46E++6DHj2yjsi5wkizGW++rbC6AhcDPwZWr1puZrX2O2pmSyWdDjxO\nqG8ZaWaTJZ0aVtsIM5sS+9V6HVgKjMhNHs41xPz5cPzxYaCn8eNhk02yjsi5piGvKxBJzwNDgH8A\nBwMnAC3M7IJ0w1shBr8CcXU2dSocemgYi/zKK2HVVbOOyLnCKoYbCdcws6cICWeGmZUDB6URkHON\n5ZFHYI894Mwz4Z//9OThXGPLtxJ9cbwpcGoskpoNrJVeWM7Vn1kYSvbKK0N9xx57ZB2Rc01TvkVY\nuwCTgXWBYUAb4FIzG5dueCvE4EVYbqUWLoQTT4T33w9jd3TokHVEzmUrzSIsH5HQNRkffBDu79hu\nuzDg0+qrr/QhzjV5mdeBSNpZ0r8kTZD0etVfGgE5Vx9PPw09e8IJJ8CoUZ48nCuEfOtAbgfOAt5g\neWeKzmXOLNR1XHxxGKd8n32yjsi55iPfBDLPzOpzJ7pzqfn2WzjtNJg4EV56CTp1yjoi55qXfBNI\nuaSRwJOs2BfW/alE5dxKzJoFRxwRksaLL0Lr3B7ZnXOpyzeB9Ae6xe2T44F4AnEF98IL0KdPuL/j\n7LNBqVQPOudWJt8EsrOZdUs1EufycP31MHgw3HILHHBA1tE417zlm0BelPRj76PKZeW77+CMM+DZ\nZ8MVSNeuWUfknMs3gfQkjAcynVAHIkJniNumFplz0UcfwZFHwvrrw7hxsM46WUfknIP8E0jvVKNw\nrgbjx4fK8l//Gi64AFr4SLPOFY2V3okex/R4y8y2KkxINcbhd6I3M7fcAn/6E9xwQ7jD3DlXd5mO\nBxLH9HhH0mZm9mEaQTiX9P33IXH8979QUQHdu2cdkXOuOvkWYbUF3pL0MrCwaqGZHZJKVK7ZmjcP\n+vYNXa+//DK0bZt1RM65muSbQAbX9wCSegOXs3xEwuE56/cGHgTej4vuN7M/1/d4rnRNmhSKqvr2\nhYsugpYts47IOVebvBKImY2VtDGwS1z0spl9srLHxTFEriaMiT4HGC/pQTObkrPps34107zddRec\nfjpcdRX065d1NM65fOTbG+8vgZeBPsAvgf9JOjKPh/YApsZRDJcAY4BDqztEnvG6JmbpUhg4MPw9\n8YQnD+dKSb5FWOcDu1RddUjakNAv1r0reVx7YGZifhYhqeT6P0mvEUY6PMtvWGwevvgCjj4aFi8O\nzXU32CDriJxzdZFvq/oWOUVWn9XhsSvzKrCZmW1PKO56oJH264rY22/DrrtCt27w2GOePJwrRfle\ngTwq6THgzjjfF3g4j8fNBjZLzHeIy5Yxs68T049IulbSemb2ee7OysvLl02XlZVRVlaWZ/iumDz4\nIJx0Evz1r9C/f9bRONe0VFRUUFFRUZBj1XojoaTVzGxxnD4C2COues7M/rXSnYebEN8hVKLPJdSj\nHGVmkxPbbGxmH8fpHsDdZrZ5NfvyGwlLXGUlDBsGN94I990HPaorzHTONaosbyR8CdhR0mgzO446\ndt8eb0J+tkBIAAAVh0lEQVQ8HXic5c14J0s6Nay2EcCRkv4fsARYRLi6cU3MggVw/PHwySehvmOT\nTbKOyDnXUCu7AnkT+AswjDCk7QoKOaCUX4GUrqlTw/0de+wRmumuumrWETnXfGR5BXIacAywLnBw\nzjofUMqt1KOPhiuPYcPg1FOzjsY515jy6UyxBXCumV1UmJBqjMOvQEqIGVx6KVxxBdx9d7j6cM4V\nXppXICtNIDGAiWa2QxoB5MsTSOlYuDB0vz5tGtx/P/zoR1lH5FzzlWYCyfdejqck/ULy0add7T74\nAHbfPdRzPPusJw/nmrJ8r0AWAK2BpYSWUlUjEhZsbDi/Ail+Tz8d7iw/99ww/Kz/3HAue5mOBwJg\nZmuncXDXNJjBlVfCxRfD7bdDr15ZR+ScK4S8EkgsujoG6GRmwyT9CNjUzF5ONTpX9L79Fk47DSZO\nhJdegk6dso7IOVco+daBXAv8H3B0nP8auCaViFzJmDUL9toLFi2CF1/05OFcc5NvAtnVzH4LfAtg\nZl8AfjtYM/bCC6ErkiOOgDFjoHXrrCNyzhVavp0pLon9Whks6869MrWoXFEbMQIGDYJbboEDDsg6\nGudcVvJNIFcC/wI2knQRcCQwKLWoXFH67rvQuurZZ+H552HLLbOOyDmXpbya8QJI2orQq66Ap5I9\n6haCN+PN1scfw5FHwnrrwejRsE7BGnA75xois2a8klYn9IfVBXgDuN7Mvk8jEFe8xo+HX/wCTjwR\nLrgAWjTWUGLOuZK2siKsWwjdrD8HHABsDfwu7aBc8bj1VvjjH0O9x+GHZx2Nc66YrCyB/NjMtgGQ\nNJIwIJRrBr7/Hs46C/7zH6iogO7ds47IOVdsVpZAllRNmNn33hVW8zBvHvTtC61awcsvQ9u2WUfk\nnCtGKyvN3k7S/Pi3ANi2alrS/HwOIKm3pCmS3pV0Ti3b7SJpSRw612Vk0iTYZRfYeWf47389eTjn\nalbrFYiZtWzIzuNYIlcTWm/NAcZLetDMplSz3SXAYw05nmuYu++G3/42jBrYr1/W0Tjnil2+94HU\nVw9gqpnNAJA0BjgUmJKz3QDgXmCXlONx1Vi6NNwYeOed8PjjsEOmI78450pF2gmkPTAzMT+LkFSW\nkdQOOMzMfipphXUufV9+GbpgX7QoNNfdcMOsI3LOlYq0E0g+LgeSdSM11tSXl5cvmy4rK6OsrCy1\noJqDt9+Gww4L3ZFcdlmoNHfOlbaKigoqKioKcqy870Sv186lnkC5mfWO8wMJA1ENT2zzftUksAGw\nEDjFzB7K2Zffid6IHnwQTjopjFt+wglZR+OcS0vmY6LXe+ehA8Z3CJXocwn3kRxVUzcokm4G/m1m\n91ezzhNII6ishGHD4MYb4d57Yddds47IOZemzEckrC8zWyrpdOBxQpPhkWY2WdKpYbWNyH1ImvE0\ndwsWwPHHh36tXn4ZNt0064icc6Us1SuQxuRXIA3z3ntw6KGw++6hme5qq2UdkXOuENK8AvFu8ZqB\nRx+F3XaDAQNCn1aePJxzjaEYWmG5RjR9+gwGDx7F7NmVtGvXgg4d+jN6dEfuuw/23DPr6JxzTYkn\nkCZk+vQZ7LffVUybNhRoDSxk1VWH8PTTA9h9945Zh+eca2K8CKsJGTx4VCJ5ALTmu++Gct11ozKM\nyjnXVHkCaSLM4M03K1mePKq0Zs4cH77eOdf4PIGUOLPQa+5uu8H777cg3IeZtJB27fxtds41Pv9m\nKVGVlXD//bDTTnDuufD738OECf3p3HkIy5PIQjp3HsKwYf2zC9Q512T5fSAlZulSuOceuOii0Bx3\n0CA45JDl45RXtcKaMye0who2rD+dOnkFunPNVcl2ZdKYmnsCWbIE7rgD/vIXWH99GDwYevcGHyTS\nOVebku3KxDXc4sVwyy1wySXQsSNcdx389KeeOJxz2fMEUqQWLYKRI0NvuT/+Mdx6K+yxR9ZROefc\ncp5AiszXX8P118Pf/hbGJr/vvvDfOeeKjSeQIjF/Plx9NVxxBey9NzzyCGy3XdZROedczTyBZOzz\nz0PSuOaaMDLgM8+EIivnnCt2fh9IRj75BAYOhK5dYdYsGDcORo/25OGcKx2eQAps7lz4wx9gq61C\nsdWrr4bK8i5dso7MOefqJvUEIqm3pCmS3pV0TjXrD5E0SdJESa9I2iftmLLw4Yfw299C9+6h+5E3\n3oBrr4XNN886Muecq59UE4ikFsDVwM+A7sBRkrbK2exJM9vOzHYATgByh7ktadOmwUknwfbbw1pr\nweTJ8I9/QPv2WUfmnHMNk/YVSA9gqpnNMLMlwBjg0OQGZvZNYnYtYF7KMRXElClh/PFdd4V27WDq\nVBg+HDbeOOvInHOucaSdQNoDMxPzs+KyFUg6TNJk4GHgjJRjahTTp8/g2GOH8tOfDuHYY4cyffoM\nAF5/Hfr2hb32gm7dwhXIhReG7kecc64pKYpmvGb2APCApD2A0UC36rYrLy9fNl1WVkZZWVkhwvuB\n6kb+Gzt2CFttNYA33+zIH/8YKsbXWiuT8JxzzVhFRQUVFRUFOVaqnSlK6gmUm1nvOD8QMDMbXstj\npgE9zOyznOVF05nisccO5fbb/8SKgzctZKedLuO554awxhpZReaccytKszPFtIuwxgNdJHWUtCrQ\nD3gouYGkzonpHQFyk0exmT27+pH/1lmn0pOHc67ZSLUIy8yWSjodeJyQrEaa2WRJp4bVNgL4haTj\nge8IIyH1TTOmxrDpplUj/614BeIj/znnmhMfD6SOFi+Gww6bwdixV7Fo0fI6kM6dh/DEEwN88Cbn\nXFHx8UCKxIIFcNhh0LZtRyZOHMCwYZclRv7z5OGca178CiRPn34KBx4IO+4Y7iBv2TKzUJxzLm+l\nXIneJHz4Iey5J+y/P/zzn548nHMOPIGs1OTJYSTAU0+Fiy7yoWSdc66K14HU4n//g0MPDcPKHn98\n1tE451xx8QRSgyeegKOPhptugoMPzjoa55wrPl6EVY2774ZjjoH77/fk4ZxzNfErkBzXXQd//nO4\nAvExyZ1zrmaeQCKzkDhGjYJnn4XOnVf6EOeca9Y8gQCVlfD730NFBTz/PGy6adYROedc8Wv2CWTJ\nEjjhBJgxA8aOhXXXzToi55wrDc06gXzzDfTpE+7teOwxWHPNrCNyzrnS0awSyPTpMxg8eBSzZ1ey\nwQYteP/9/nTv3pGRI6FVq6yjc8650tJsEkh1owi2aTOEu+8eQKtW3gmic87VVbO5D2Tw4FGJ5AHQ\nmq++GsqQIaMyjMo550pXs0kgNY0iOGdOZRbhOOdcyUs9gUjqLWmKpHclnVPN+qMlTYp/z0vaJo04\n2revGkUwyUcRdM65+kp1PBBJLYB3gV7AHMIY6f3MbEpim57AZDP7SlJvoNzMelazrwaNBzJ9+gy2\n3fYqvv7aRxF0zjUfpTwiYQ9gqpnNAJA0BjgUWJZAzGxcYvtxQPs0Apk/vyOrrz6AAw+8jE8/9VEE\nnXOuodJOIO2BmYn5WYSkUpOTgEfSCGTwYBg0qCNnnjkkjd0751yzUzTNeCX9FDgB2KOmbcrLy5dN\nl5WVUVZWlte+X3oJXnst9LLrnHNNWUVFBRUVFQU5Vtp1ID0JdRq94/xAwMxseM522wL3Ab3NbFoN\n+6pXHYgZ7LMPHHss/PrXdX64c86VtFIeE3080EVSR0mrAv2Ah5IbSNqMkDyOqyl5NMRTT8Hs2fCr\nXzX2np1zrnlLtQjLzJZKOh14nJCsRprZZEmnhtU2AhgMrAdcK0nAEjOrrZ6kDseH88+HYcNglaIp\nrHPOuaYh1SKsxlSfIqwHH4QhQ2DCBGjht3s455qhUm7Gm5mlS2HQILj4Yk8ezjmXhib71TpmDKy9\nNhx0UNaROOdc09Qki7CWLIGtt4Ybb4Q8W/o651yTVMqtsDJx882wxRaePJxzLk1N7gpk0SLo2hXu\nvx96NEpbLuecK11eiZ6HqtEGx42rRGrBhhv2B7yfK+ecS0uTuAKpbrRB72nXOefSvQIpyQSSHNu8\nffsWLFjwNQ89VM6KA0Yt5JhjLuO227zzROdc8+VFWNH06TP4/e8v57HHvuLbb6+i6mqjRYtT8NEG\nnXOusEoqgWyxxXnAFsCfSY5tXlm5BWG0wRWvQHy0QeecS0+JfcOOIISce7VxEmusMYDlQ9aGOpBh\nw/oXMDbnnGteSuoKJCSOqrHNk0lkA/bfvw1rrXUZc+b4aIPOOVcIJVWJDl8D84CrAG9x5ZxzK+Ot\nsKhKIH8kJI55wI2svvr77L9/Oy6//HRPHs45Vw1PIFQlkA+AG4Ep7LvvxowYcZYnDuecq0VJ94Ul\nqbekKZLelXRONeu7SXpR0reS/lD73s6kTZsXGTv2dzzxxNWePJxzLkOpJhBJLYCrgZ8B3YGjJG2V\ns9lnwADgryvbn9kDfPnlU+y11+6NHmt9FGrg+roqxrg8pvx4TPkrxriKMaY0pX0F0gOYamYzzGwJ\nMAY4NLmBmc0zs1eB71OOpdEV68lSjHF5TPnxmPJXjHEVY0xpSjuBtAdmJuZnxWXOOedKXIndSOic\nc65YpNoKS1JPoNzMesf5gYCZ2fBqth0CLDCzv9ewr9JoLuacc0WmVDtTHA90kdQRmAv0A46qZfsa\nn2RaL4Bzzrn6Sf0+EEm9gSsIxWUjzewSSacSrkRGSNoYeAVYG6gk3G7+YzP7OtXAnHPONUjJ3Ejo\nnHOuuJREJfrKbkZsxON0kPS0pLckvSHpjLi8raTHJb0j6TFJbRKPOVfSVEmTJe2fWL6jpNdjzJc3\nQmwtJE2Q9FARxdRG0j3xOG9J2jXruOIx3or7u13SqoWOSdJISR9Lej2xrNFiiM9pTHzMS5I2a0Bc\nl8bjvibpPknrFDKu6mJKrPujpEpJ6xVDTJIGxOO+IemSrGOStIuklyVNjP93LmRMAJhZUf8Rktx7\nhAHOWwGvAVuldKxNgO3j9FrAO8BWwHDg7Lj8HOCSOP1jYCKhLmnzGGfVVd3/gF3i9MPAzxoY2++B\n24CH4nwxxDQKOCFOrwK0yTKueI68D6wa5+8CflXomIA9gO2B1xPLGi0G4P8B18bpvsCYBsS1L9Ai\nTl8CXFzIuKqLKS7vADwKTAfWi8u2ziomoAx4HFglzm9QBDE9A+wfpw8Anin4OVWfD2oh/4CewCOJ\n+YHAOQU69gPxAzYF2Dgu2wSYUl0swCPArnGbtxPL+wHXNSCODsAT8SSuSiBZx7QOMK2a5ZnFBbSN\nx28bPzwPZfX+EZJZ8sPeaDEQvlh3jdMtgU/rG1fOusOA0YWOq7qYgHuAbVgxgWQWE+HHyD7VbJdl\nTHcAfeL0UcBthY6pFIqwMrkZUdLmhIw/jvDB/xjAzD4CNqohttlxWfsYZ5WGxvwP4CzAEsuyjqkT\nME/SzQpFayMkrZllXGb2BfA34MO4/6/M7MksY0rYqBFjWPYYM1sKfJks5mmAEwm/SjONS9IhwEwz\neyNnVZav1ZbAXpLGSXpG0k5FENNA4O+SPgQuBc4tdEylkEAKTtJawL3AmRZag1nOJrnzacZyEPCx\nmb1GLc2cKWBM0SrAjsA1ZrYjYZSvgdXEUcjXagtCUV9HoB3QWtIxWcZUi8aMocFN3CWdDywxszsb\nIZ5lu61HHGsA5wFDGjGOFQ5Rz8etArQ1s57A2YQrpMZS35hGAgPMbDPCeX9T44WUX0ylkEBmA8kK\nnQ5xWSokrUJIHqPN7MG4+GOF5sZI2gT4JBHbj6qJrabl9bE7cIik94E7gX0kjQY+yjAmCL9eZprZ\nK3H+PkJCyfK12hl4wcw+j7+i/gXslnFMVRozhmXrJLUE1jGzz+sbmKT+wIHA0YnFWcXVmVBuP0nS\n9Lj/CZI2oubvgkK8VjOB+wHMbDywVNL6Gce0q5k9EGO6F9gld/9px1QKCWTZzYiSViWU2z2U4vFu\nIpQTXpFY9hDQP07/CngwsbxfbMHQCegCvByLKL6S1EOSgOMTj6kTMzvPzDYzsy0Iz/1pMzsO+HdW\nMcW4PgZmStoyLuoFvEWGrxWh0UNPSavHffUC3s4oJrHir7jGjOGhuA+APsDT9Y1L4T6ts4BDzGxx\nTryFimtZTGb2ppltYmZbmFknwg+VHczsk7j/voWOKXoA2AcgnvOrmtlnGcc0VdLeMaZewNTE/gvz\n3uVTUZL1H9Cb8OUwFRiY4nF2B5YSWnpNBCbEY68HPBljeBxYN/GYcwmtHCYTW0TE5TsBb8SYr2ik\n+PZmeSV65jEB2xES/GuEX2dtso6L8GX4FvA6cAuh5V5BYyJUbs4BFhPqY04gVOw3SgzAasDdcfk4\nYPMGxDUVmBHP9QnEljiFiqu6mHLWv0+sRM8yJkIR1uh4jFeAvYsgpp0IraomAi8REm1Bzym/kdA5\n51y9lEIRlnPOuSLkCcQ551y9eAJxzjlXL55AnHPO1YsnEOecc/XiCcQ551y9eAJxTZpCd+C3JuZb\nSvpUsVv8Ouxn+sr6BqppG0knxi60J8X/B8flQyXtU5c4nCsmaQ9p61zWFgI/kbSahTut92PFjuby\nlc8NUz/YRlJ7Qt9O25vZ17HDyQ0BzCyt/p6cKwi/AnHNwcPAQXH6KEKfYsCygZ7+Fa8OXpS0TVy+\nnsLAT29IuoEVu/84RtL/Yi/E18VuIYBqO6DbCJgPfANgZt+Y2Yy4n5slHSFpJ4VBgSbEK5Slcf0W\nkh6RNF7S2ES3Mc4VBU8grqkzYAxwlKTVgG0J3T9UGQpMMLPtgPOBquKuIcBzZrYNoVPGzQAkbUUY\ncGc3C70QVwLH1HL8SYSOE6dLuknSz38QoNmrZrZD3N+jwF/jqhHA6Wa2C6GLluvq/OydS5EXYbkm\nz8zeVBjf5Sjgv6x4pbAHcETc7pl45bE2sBdweFz+sKQv4va9CL0Oj49XHqsDH9Vy7Eqgt8Jwo70I\n4zfsaGYX5m4rqS+wA7C/pNaEnoTvSVzhtKrP83cuLZ5AXHPxEOGXfRmwwUq2ra6+I1lMdYuZnV+X\ng1vo9v4VSU8SenxeIYFI+glwAbCnmZmkFsAX8arEuaLkRViuqav64r8JGGpmb+Wsfw44FkBSGTDP\nwiBizxKLpiQdAKwbt38KOFLShnFdW0mbUQNJm0raIbFoB0Lvt8lt2hB6Wz3e4hgMZraAUOx1ZGK7\nbfN90s4Vgl+BuKbOAMxsNnB1NevLgZskTSK02KoaE2EocKekfsCLhC60MbPJkgYBj8erhO+A38b1\n1V25tAIuk7Qp8C3wKXBaMjbgUEIdyw2xuMrilcexwHXxeKsQ6nJer8+L4FwavDt355xz9eJFWM45\n5+rFE4hzzrl68QTinHOuXjyBOOecqxdPIM455+rFE4hzzrl68QTinHOuXjyBOOecq5f/D98MBWc8\noXhRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134f54510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def performance(cfd, wordlist):\n",
    "    lt = dict((word, cfd[word].max()) for word in wordlist)\n",
    "    baseline_tagger = nltk.UnigramTagger(model=lt, backoff=nltk.DefaultTagger('NN'))\n",
    "    return baseline_tagger.evaluate(brown.tagged_sents(categories='news'))\n",
    "\n",
    "def display():\n",
    "    import pylab\n",
    "    words_by_freq = list(nltk.FreqDist(brown.words(categories='news')))\n",
    "    cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
    "    sizes = 2 ** pylab.arange(15)\n",
    "    perfs = [performance(cfd, words_by_freq[:size]) for size in sizes]\n",
    "    pylab.plot(sizes, perfs, '-bo')\n",
    "    pylab.title('Lookup Tagger Performance with Varying Model Size')\n",
    "    pylab.xlabel('Model Size')\n",
    "    pylab.ylabel('Performance')\n",
    "    pylab.show()\n",
    "\n",
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 5-4. Lookup tagger\n",
    "\n",
    "## N-gram标注\n",
    "### 一元标注器(`Unigram Tagging`)\n",
    "一元标注器利用一种简单的统计算法，对每个标识符分配最有可能的标记。建议一元标注器，称为训练(`training`)。下面例子中，“训练”一个一元标注器，用它来标注一个句子，然后进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Various', u'JJ'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'apartments', u'NNS'),\n",
       " (u'are', u'BER'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'terrace', u'NN'),\n",
       " (u'type', u'NN'),\n",
       " (u',', u','),\n",
       " (u'being', u'BEG'),\n",
       " (u'on', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'ground', u'NN'),\n",
       " (u'floor', u'NN'),\n",
       " (u'so', u'QL'),\n",
       " (u'that', u'CS'),\n",
       " (u'entrance', u'NN'),\n",
       " (u'is', u'BEZ'),\n",
       " (u'direct', u'JJ'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "unigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349006503968017"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分离训练和测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4160"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8120203329014253"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "unigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一般的N-gram的标注\n",
    "A `1-gram tagger` is another term for a `unigram tagger`: i.e., the context used to tag a token is just the text of the token itself. `2-gram taggers` are also called `bigram taggers`, and `3-gram taggers` are called `trigram taggers`.\n",
    "\n",
    "bigram标注器，首先训练它，然后用它来标注未标注的句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Various', u'JJ'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'apartments', u'NNS'),\n",
       " (u'are', u'BER'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'terrace', u'NN'),\n",
       " (u'type', u'NN'),\n",
       " (u',', u','),\n",
       " (u'being', u'BEG'),\n",
       " (u'on', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'ground', u'NN'),\n",
       " (u'floor', u'NN'),\n",
       " (u'so', u'CS'),\n",
       " (u'that', u'CS'),\n",
       " (u'entrance', u'NN'),\n",
       " (u'is', u'BEZ'),\n",
       " (u'direct', u'JJ'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "bigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'The', u'AT'),\n",
       " (u'population', u'NN'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'Congo', u'NP'),\n",
       " (u'is', u'BEZ'),\n",
       " (u'13.5', None),\n",
       " (u'million', None),\n",
       " (u',', None),\n",
       " (u'divided', None),\n",
       " (u'into', None),\n",
       " (u'at', None),\n",
       " (u'least', None),\n",
       " (u'seven', None),\n",
       " (u'major', None),\n",
       " (u'``', None),\n",
       " (u'culture', None),\n",
       " (u'clusters', None),\n",
       " (u\"''\", None),\n",
       " (u'and', None),\n",
       " (u'innumerable', None),\n",
       " (u'tribes', None),\n",
       " (u'speaking', None),\n",
       " (u'400', None),\n",
       " (u'separate', None),\n",
       " (u'dialects', None),\n",
       " (u'.', None)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sent = brown_sents[4203]\n",
    "bigram_tagger.tag(unseen_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10276088906608193"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它的准确度非常低。\n",
    "\n",
    "### 组合标注器\n",
    "- 尝试使用bigram标注器标注标识符。\n",
    "- 如果bigram标注器无法找到标记，尝试unigram标注器。\n",
    "- 如果unigram标注器也无法找到标记，使用默认标注器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.844911791089405"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标注生词\n",
    "标注生词的方法是回退(`backoff`)到正则表达式标注器或默认标注器。\n",
    "\n",
    "### 存储标注器\n",
    "```py\n",
    ">>> from cPickle import dump\n",
    ">>> output = open('t2.pkl', 'wb')\n",
    ">>> dump(t2, output, -1)\n",
    ">>> output.close()\n",
    "\n",
    ">>> from cPickle import load\n",
    ">>> input = open('t2.pkl', 'rb')\n",
    ">>> tagger = load(input)\n",
    ">>> input.close()\n",
    "\n",
    ">>> text = \"\"\"The board's action shows what free enterprise\n",
    "...     is up against in our complex maze of regulatory laws .\"\"\"\n",
    ">>> tokens = text.split()\n",
    ">>> tagger.tag(tokens)\n",
    "[('The', 'AT'), (\"board's\", 'NN$'), ('action', 'NN'), ('shows', 'NNS'),\n",
    "('what', 'WDT'), ('free', 'JJ'), ('enterprise', 'NN'), ('is', 'BEZ'),\n",
    "('up', 'RP'), ('against', 'IN'), ('in', 'IN'), ('our', 'PP$'), ('complex', 'JJ'),\n",
    "('maze', 'NN'), ('of', 'IN'), ('regulatory', 'NN'), ('laws', 'NNS'), ('.', '.')]\n",
    "```\n",
    "\n",
    "### 性能限制\n",
    "参考trigram标注器。它遇到多少词性歧义的情况？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049297702068029296"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    ((x[1], y[1], z[0]), z[1])\n",
    "    for sent in brown_tagged_sents\n",
    "    for x, y, z in nltk.trigrams(sent))\n",
    "ambiguous_contexts = [c for c in cfd.conditions() if len(cfd[c]) > 1]\n",
    "sum(cfd[c].N() for c in ambiguous_contexts) / cfd.N()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/20的trigrams是歧义的。给定当前单词及其前两个标记，根据训练数据，在5%的情况中，可能有一个以上的标记合理地分配给当前词。\n",
    "\n",
    "一种便捷查看标注错误的方法是混淆矩阵(`confusion matrix`)，它利用图表表示期望的标记(黄金标准)与实际由标注器产生的标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tags = [tag for sent in brown.sents(categories='editorial')\n",
    "             for (word, tag) in t2.tag(sent)]\n",
    "gold_tags = [tag for (word, tag) in brown.tagged_words(categories='editorial')]\n",
    "# print nltk.ConfusionMatrix(gold_tags, test_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 跨句子边界标注\n",
    "使用已标注句子的链表来训练、运行和评估标注器。\n",
    "\n",
    "句子层面的N-gram标注。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.844911791089405"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "\n",
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "\n",
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于转换的标注(Transformation-Based Tagging)\n",
    "Brill标注是一种基于转换的学习。一般的想法是：猜测每个词的标记，然后返回和修复错误的。在这种方式中，Brill标注器陆续将一个不良标注的文本转换成一个好的。与n-gram标注一样，需要监督整个过程。\n",
    "\n",
    "Brill标注器的另一个特性：规则是语言学可解释的。\n",
    "\n",
    "Brill标注器演示：标注器有一个“X->Y如果前面的词是Z”的形式的模板集合。这些模板中的变量是创建“规则”的特定词和标记的实例。得分规则是纠正错误例子的数目减去误报的数目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tagged data from treebank... \n",
      "Read testing data (200 sents/5251 wds)\n",
      "Read training data (800 sents/19933 wds)\n",
      "Read baseline data (800 sents/19933 wds) [reused the training set]\n",
      "Trained baseline tagger\n",
      "    Accuracy on test set: 0.8345\n",
      "Training tbl tagger...\n",
      "TBL train (fast) (seqs: 800; tokens: 19933; tpls: 24; min score: 3; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 12960 useful rules.\n",
      "\n",
      "           B      |\n",
      "   S   F   r   O  |        Score = Fixed - Broken\n",
      "   c   i   o   t  |  R     Fixed = num tags changed incorrect -> correct\n",
      "   o   x   k   h  |  u     Broken = num tags changed correct -> incorrect\n",
      "   r   e   e   e  |  l     Other = num tags changed incorrect -> incorrect\n",
      "   e   d   n   r  |  e\n",
      "------------------+-------------------------------------------------------\n",
      "  23  23   0   0  | POS->VBZ if Pos:PRP@[-2,-1]\n",
      "  16  17   1   0  | NN->VB if Pos:-NONE-@[-2] & Pos:TO@[-1]\n",
      "  15  16   1   0  | VBN->VBD if Pos:PRP@[-1]\n",
      "  12  12   0   0  | VBP->VB if Pos:MD@[-2,-1]\n",
      "  10  10   0   0  | VB->VBP if Pos:PRP@[-1]\n",
      "   9   9   0   1  | VB->NN if Pos:DT@[-1]\n",
      "   9   9   0   0  | VBD->VBN if Pos:VBD@[-1]\n",
      "   9  15   6   0  | IN->WDT if Pos:NNS@[-1] & Pos:-NONE-@[1]\n",
      "   7   7   0   1  | VB->VBP if Pos:NNS@[-1]\n",
      "   7   7   0   0  | VBP->VB if Pos:TO@[-1]\n",
      "   7   8   1   0  | IN->RB if Word:as@[2]\n",
      "   6   6   0   0  | NN->VB if Pos:MD@[-1]\n",
      "   6   7   1   0  | VBD->VBN if Pos:VBZ@[-1]\n",
      "   6   6   0   0  | WDT->IN if Pos:VBG@[2]\n",
      "   6   6   0   0  | IN->WDT if Pos:-NONE-@[1] & Pos:VBZ@[2]\n",
      "   5   5   0   0  | POS->VBZ if Pos:-NONE-@[-1]\n",
      "   5   7   2   3  | RP->RB if Pos:CD@[1,2]\n",
      "   5   5   0   1  | IN->WDT if Pos:-NONE-@[1] & Pos:VBD@[2]\n",
      "   4   5   1   3  | VB->NN if Pos:NN@[-1]\n",
      "   4   4   0   0  | POS->VBZ if Pos:``@[-2]\n",
      "   4   4   0   0  | VBD->VBN if Pos:VBP@[-2,-1]\n",
      "   4   4   0   0  | VBP->VB if Pos:VBD@[-2,-1]\n",
      "   4   4   0   0  | NN->VBP if Pos:NNS@[-2] & Pos:RB@[-1]\n",
      "   4   5   1   0  | VBN->VBD if Pos:NNP@[-2] & Pos:NNP@[-1]\n",
      "   4   4   0   0  | IN->WDT if Pos:-NONE-@[1] & Pos:MD@[2]\n",
      "   4   4   0   0  | JJS->RBS if Word:most@[0] & Word:the@[-1] & Pos:DT@[-1]\n",
      "   3   3   0   1  | VB->NN if Pos:JJ@[-1]\n",
      "   3   3   0   0  | VB->NN if Pos:POS@[-1]\n",
      "   3   3   0   0  | VBD->VBN if Pos:VBN@[-1]\n",
      "   3   4   1   0  | VBN->VB if Pos:TO@[-1]\n",
      "   3   4   1   1  | IN->RB if Pos:.@[1]\n",
      "   3   3   0   0  | PRP$->PRP if Pos:TO@[1]\n",
      "   3   3   0   0  | RP->RB if Pos:DT@[-2,-1]\n",
      "   3   3   0   1  | VBD->VBN if Pos:VB@[-2,-1]\n",
      "   3   3   0   0  | NN->VBP if Pos:NNS@[-1] & Pos:DT@[1]\n",
      "   3   3   0   0  | RB->JJ if Pos:DT@[-1] & Pos:NN@[1]\n",
      "   3   3   0   0  | VBP->VB if Word:n't@[-2,-1]\n",
      "Trained tbl tagger in 7.09 seconds\n",
      "    Accuracy on test set: 0.8551\n",
      "Tagging the test data\n"
     ]
    }
   ],
   "source": [
    "from nltk.tbl import demo as brill_tagger\n",
    "brill_tagger.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何确定一个词的分类\n",
    "### 形态学(Morphological)线索\n",
    "一个词的内部结构有助于为这个词分类。举例来说：-ness是一个后缀，与形容词结合产生名词，如happy->happiness,ill->illness。所以，如果遇到一个以-ness结尾的词，很可能是一个名词。同样的，-ment是与一些动词结合产生名词的后缀，如govern->government和establish->establishment。\n",
    "\n",
    "英语动词也可以是形态复杂的。例如：一个动词的现在分词以-ing结尾，表示正在进行的还没有结束的行动（如：falling、eating）。-ing后缀也出现在从动词派生的名词中，如：the falling of the leaves（这被称为动名词）。\n",
    "\n",
    "### 句法(Syntactic)线索\n",
    "另一个线索是一个词可能出现的典型的上下文语境。例如：假设已经确定了名词类，那么，英语形容词的句法标准是它可以出现在一个名词前，或紧跟在词be或very后。\n",
    "\n",
    "### 语义(Semantic)线索\n",
    "最后一个线索是词的意思。例如：名词众所周知的一个定义是根据语义的：“一个人、地方或事物的名称。”\n",
    "\n",
    "### 新词\n",
    "名词被称为开放类(`open class`)。介词被认为是封闭类(`closed class`)。\n",
    "\n",
    "### 词性标注集中的形态学(Morphology in Part-of-Speech Tagsets)\n",
    "普通标记集经常会“捕捉”一些构词(`morphosyntactic`)信息，即一种词借助句法角色获得的形态标记信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
