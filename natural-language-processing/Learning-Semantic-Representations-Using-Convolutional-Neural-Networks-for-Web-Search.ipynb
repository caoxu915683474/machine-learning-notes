{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Semantic Representations Using Convolutional Neural Networks for Web Search\n",
    "\n",
    "    Yelong Shen\n",
    "    Xiaodong He\n",
    "    Jianfeng Gao\n",
    "    Li Deng\n",
    "    Gr√©goire Mesnil\n",
    "\n",
    "    WWW‚Äô14 Companion, April 7‚Äì11, 2014\n",
    "\n",
    "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/www2014_cdssm_p07.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÊÄªÁªì\n",
    "Áõ∏ÊØîDSSMÔºö\n",
    "\n",
    "1. ‰ΩøÁî®‰∏Ä‰∏™Âç∑ÁßØÂ±ÇÂæóÂà∞ local contextual features\n",
    "1. ‰ΩøÁî®‰∏Ä‰∏™max-poolingÂ±ÇÂæóÂà∞global feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION\n",
    "In this study, based on a convolutional neural network, we present a new Convolutional Deep Structured Semantic Models (C-DSSM). Compared with DSSM, C-DSSM has a convolutional layer that projects each word within a context window to a local contextual feature vector. Semantically similar words-within-context are projected to vectors that are close to each other in the contextual feature space. Further, since the overall semantic meaning of a sentence is often determined by a few key words in the sentence, thus, simply mixing all words together (e.g., by summing over all local feature vectors) may introduce unnecessary divergence and hurt the effectiveness of the overall semantic representation. Therefore, C-DSSM uses a max pooling layer to extract the most salient local features to form a fixed-length global feature vector. The global feature vector can be then fed to feedforward neural network layers, which perform affine transformations followed by non-linear functions applied element-wise over their inputs to extract highly non-linear and effective features.\n",
    "\n",
    "## C-DSSM FOR EXTRACTING CONTEXTUAL FEATURES FOR IR\n",
    "![1](http://ou8qjsj0m.bkt.clouddn.com//17-8-6/36195676.jpg)\n",
    "\n",
    "- The C-DSSM contains a word hashing layer that transforms each word into a letter-tri-gram input representation\n",
    "- a convolutional layer to extract local contextual features\n",
    "- a max-pooling layer to form a global feature vector\n",
    "- a final semantic layer to represent the high-level semantic feature vector of the input word sequence\n",
    "\n",
    "Formally, the semantic relevance score between a query ùëÑ and a document ùê∑ is measured as:\n",
    "\n",
    "$R(Q,D)=cosine(y_Q,y_D)=\\frac{y_Q^T y_D}{\\lVert y_Q \\rVert\\lVert y_D \\rVert}$\n",
    "\n",
    "where $y_Q$ and $y_D$ vectors of the query and the document, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
